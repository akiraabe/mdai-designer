# src/mdai_mcp_server/ai_service.py
"""
AI Service for MCP Server
WebUIã®aiServiceã¨åŒç­‰ã®æ©Ÿèƒ½ã‚’MCPã‚µãƒ¼ãƒãƒ¼å´ã§æä¾›
"""

import os
import json
from typing import Dict, Any, Optional
from datetime import datetime
import re
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# AI APIs
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import boto3
    from botocore.exceptions import ClientError
    BEDROCK_AVAILABLE = True
except ImportError:
    BEDROCK_AVAILABLE = False

class AIService:
    """AIç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIè¨­å®šã‚’èª­ã¿è¾¼ã¿
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        self.aws_region = os.getenv('AWS_REGION', 'us-west-2')
        
        # å„ªå…ˆåº¦é †ã§AIã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­å®š
        self.ai_providers = []
        
        if BEDROCK_AVAILABLE and self.aws_access_key:
            self.ai_providers.append('bedrock')
        
        if OPENAI_AVAILABLE and self.openai_api_key:
            self.ai_providers.append('openai')
        
        print(f"ğŸ¤– AI Service initialized with providers: {self.ai_providers}")
        print(f"ğŸ”§ Debug info:")
        print(f"   OpenAI available: {OPENAI_AVAILABLE}")
        print(f"   Bedrock available: {BEDROCK_AVAILABLE}")
        print(f"   OpenAI key set: {'Yes' if self.openai_api_key else 'No'}")
        print(f"   AWS key set: {'Yes' if self.aws_access_key else 'No'}")
    
    async def generate_data_model(
        self, 
        prompt: str, 
        project_context: Optional[Dict] = None,
        references: Optional[list] = None,
        current_mermaid_code: str = ""
    ) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆWebUIã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ï¼‰
        """
        
        print(f"ğŸ¯ AI Data Model Generation Request:")
        print(f"   Prompt: {prompt[:100]}...")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        print(f"   Current Mermaid: {'ã‚ã‚Š' if current_mermaid_code else 'æœªè¨­å®š'}")
        
        # è©³ç´°ãªMermaidãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆWebUIã‹ã‚‰ç§»æ¤ï¼‰
        mermaid_prompt = f"""
ã€çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ã€‘ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸å°‚ç”¨ã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã‚’å¿…ãšMermaid ERå›³ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚

æŒ‡ç¤º: {prompt}

ã€é‡è¦ãªè§£é‡ˆæŒ‡é‡ã€‘:
ã©ã‚“ãªæŒ‡ç¤ºã§ã‚‚ï¼ˆç”»é¢ã€UIã€æ©Ÿèƒ½ãªã©ã®å˜èªãŒã‚ã£ã¦ã‚‚ï¼‰ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ERå›³ã§è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
- ã€Œç”»é¢ã‚’ä½œã£ã¦ã€â†’ ãã®ç”»é¢ã§æ‰±ã†ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã€â†’ Userã€Sessionç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œæ³¨æ–‡ã‚·ã‚¹ãƒ†ãƒ ã€â†’ Orderã€OrderItemã€Productç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œç®¡ç†æ©Ÿèƒ½ã€â†’ ç®¡ç†ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- Mermaid ERå›³: {('ã‚ã‚Šï¼ˆè¿½åŠ ãƒ»ä¿®æ­£ï¼‰' if current_mermaid_code else 'æœªè¨­å®šï¼ˆæ–°è¦ä½œæˆï¼‰')}
- å‚ç…§è¨­è¨ˆæ›¸: {', '.join(references) if references else 'ãªã—'}

ã€å¿…é ˆã€‘erDiagramã§å§‹ã¾ã‚‹Mermaidè¨˜æ³•ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ï¼šMermaidè¨˜æ³•æ³¨æ„äº‹é …ã€‘
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã«ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆï¼ˆ`ï¼‰ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã¯è‹±æ•°å­—ã®ã¿ã§è¨˜è¿°ã—ã¦ãã ã•ã„
- SQLã®äºˆç´„èªã§ã‚‚Mermaidã§ã¯ãã®ã¾ã¾è¨˜è¿°ã—ã¦ãã ã•ã„
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚­ãƒ¼æŒ‡å®šã¯ã€ŒPKã€ã¾ãŸã¯ã€ŒFKã€ã®ã¿ï¼ˆã€ŒPK FKã€ã¯ä¸æ­£ï¼‰
- è¤‡åˆä¸»ã‚­ãƒ¼ã®å ´åˆã¯è¤‡æ•°ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãã‚Œãã‚Œã€ŒPKã€ã‚’æŒ‡å®š

ä¾‹:
erDiagram
    User {{
        int id PK
        string name
        string email
        datetime created_at
    }}
    Order {{
        int id PK
        int user_id FK
        decimal amount
        datetime order_date
    }}
    ProductCategory {{
        int product_id PK
        int category_id PK
    }}
    User ||--o{{ Order : "has many"
        """
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = await self._generate_with_ai(mermaid_prompt)
            
            # Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            mermaid_code = self._extract_mermaid_code(ai_response)
            
            if not mermaid_code:
                raise ValueError("Mermaidã‚³ãƒ¼ãƒ‰ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ
            supplement = self._generate_supplement(
                prompt, 
                mermaid_code, 
                project_context, 
                references
            )
            
            result = {
                "mermaidCode": mermaid_code,
                "supplement": supplement,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "prompt_used": prompt,
                    "mode": "ai_generated",
                    "project_context": project_context,
                    "references": references or [],
                    "server_version": "0.1.0",
                    "generation_type": "dynamic_ai_mermaid",
                    "ai_provider": self.ai_providers[0] if self.ai_providers else "none"
                }
            }
            
            print(f"âœ… AI Data Model Generated:")
            mermaid_lines = len(mermaid_code.split('\n'))
            print(f"   Mermaid lines: {mermaid_lines}")
            print(f"   Supplement chars: {len(supplement)}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI Generation Error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            return await self._generate_fallback_data(prompt, project_context, references)
    
    async def _generate_with_ai(self, prompt: str) -> str:
        """AI APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ç”Ÿæˆ"""
        
        # Bedrockã‚’å„ªå…ˆ
        if 'bedrock' in self.ai_providers:
            try:
                return await self._generate_with_bedrock(prompt)
            except Exception as e:
                print(f"âš ï¸ Bedrock generation failed: {e}")
        
        # OpenAIã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if 'openai' in self.ai_providers:
            try:
                return await self._generate_with_openai(prompt)
            except Exception as e:
                print(f"âš ï¸ OpenAI generation failed: {e}")
        
        raise ValueError("No AI providers available")
    
    async def _generate_with_bedrock(self, prompt: str) -> str:
        """AWS Bedrock ClaudeçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        bedrock = boto3.client(
            'bedrock-runtime',
            region_name=self.aws_region,
            aws_access_key_id=self.aws_access_key,
            aws_secret_access_key=self.aws_secret_key
        )
        
        body = json.dumps({
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 4000,
            "temperature": 0.7,
            "anthropic_version": "bedrock-2023-05-31"
        })
        
        response = bedrock.invoke_model(
            modelId="anthropic.claude-3-sonnet-20240229-v1:0",
            contentType="application/json",
            accept="application/json",
            body=body
        )
        
        response_body = json.loads(response['body'].read())
        return response_body['content'][0]['text']
    
    async def _generate_with_openai(self, prompt: str) -> str:
        """OpenAI GPTçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        print(f"ğŸ”µ OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹...")
        print(f"   Model: gpt-4.1")
        print(f"   API Key: {'è¨­å®šæ¸ˆã¿' if self.openai_api_key else 'æœªè¨­å®š'}")
        
        try:
            client = openai.OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model="gpt-4.1",  # ã‚³ã‚¹ãƒˆãƒ»ç²¾åº¦ãƒ»é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹æœ€é©
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.7
            )
            
            print(f"âœ… OpenAI APIæˆåŠŸ: {len(response.choices[0].message.content)}æ–‡å­—")
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ OpenAI APIå¤±æ•—: {type(e).__name__}: {str(e)}")
            raise
    
    def _extract_mermaid_code(self, ai_response: str) -> str:
        """AIå¿œç­”ã‹ã‚‰Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        mermaid_match = re.search(r'```(?:mermaid)?\s*(erDiagram[\s\S]*?)```', ai_response, re.IGNORECASE)
        if mermaid_match:
            mermaid_code = mermaid_match.group(1).strip()
        else:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãªã—ã®å ´åˆã€erDiagramã‹ã‚‰æŠ½å‡º
            mermaid_match = re.search(r'(erDiagram[\s\S]*)', ai_response, re.IGNORECASE)
            if mermaid_match:
                mermaid_code = mermaid_match.group(1).strip()
            else:
                return ""
        
        # Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®å¾Œå‡¦ç†
        mermaid_code = self._fix_mermaid_syntax(mermaid_code)
        return mermaid_code
    
    def _fix_mermaid_syntax(self, mermaid_code: str) -> str:
        """Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£"""
        
        print(f"ğŸ”§ Mermaidè¨˜æ³•ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£ä¸­...")
        
        # ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»ï¼ˆæœ€ã‚‚é‡è¦ï¼‰
        fixed_code = re.sub(r'`([^`]+)`', r'\1', mermaid_code)
        
        # ä¸æ­£ãªæ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
        if '`' in fixed_code:
            print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»: {fixed_code.count('`')}å€‹")
            fixed_code = fixed_code.replace('`', '')
        
        # ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£ï¼ˆé‡è¦ï¼‰
        pk_fk_count = len(re.findall(r'\s+PK\s+FK\s*', fixed_code))
        if pk_fk_count > 0:
            print(f"âš ï¸ ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {pk_fk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+PK\s+FK\s*', ' PK', fixed_code)
        
        # ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£
        fk_pk_count = len(re.findall(r'\s+FK\s+PK\s*', fixed_code))
        if fk_pk_count > 0:
            print(f"âš ï¸ ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {fk_pk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+FK\s+PK\s*', ' PK', fixed_code)
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®æ¤œè¨¼ï¼ˆè‹±æ•°å­—ã®ã¿ï¼‰
        entity_names = re.findall(r'^\s*([A-Za-z_][A-Za-z0-9_]*)\s*\{', fixed_code, re.MULTILINE)
        print(f"âœ… æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {', '.join(entity_names)}")
        
        return fixed_code
    
    def _generate_supplement(
        self, 
        prompt: str, 
        mermaid_code: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> str:
        """è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ"""
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ã‚’è¨ˆç®—
        entities = re.findall(r'(\w+)\s*\{', mermaid_code)
        relations = re.findall(r'\|\|--[o{].*?:', mermaid_code)
        
        supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- **ç”Ÿæˆæ–¹å¼**: AIå‹•çš„ç”Ÿæˆï¼ˆMCP Serverï¼‰

### ãƒ¢ãƒ‡ãƒ«æ¦‚è¦
{prompt}ã®è¦æ±‚ã«åŸºã¥ã„ã¦è¨­è¨ˆã•ã‚ŒãŸERå›³ã§ã™ã€‚

#### è¨­è¨ˆçµ±è¨ˆ
- **ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°**: {len(entities)}å€‹
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°**: {len(relations)}å€‹
- **æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£**: {', '.join(entities) if entities else 'ãªã—'}

#### ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´
ã“ã®ERå›³ã¯ä»¥ä¸‹ã®è¨­è¨ˆåŸå‰‡ã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼š
- **æ­£è¦åŒ–**: ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã‚’é¿ã‘ã€æ•´åˆæ€§ã‚’ä¿ã¤è¨­è¨ˆ
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é©åˆ‡ãªé–¢ä¿‚å®šç¾©
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å°†æ¥ã®æ‹¡å¼µã‚’è€ƒæ…®ã—ãŸæŸ”è»Ÿãªæ§‹é€ 

### ğŸ¤– AIç”Ÿæˆè©³ç´°
- **ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³**: MCP Server AI Integration
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–**: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç‰¹åŒ–å‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
- **å“è³ªä¿è¨¼**: Mermaidè¨˜æ³•ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯æ¸ˆã¿

### å‚ç…§æƒ…å ±
{f"å‚ç…§ã•ã‚ŒãŸè¨­è¨ˆæ›¸: {', '.join(references)}" if references else "å‚ç…§è¨­è¨ˆæ›¸: ãªã—"}

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ã€Œãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã€ã‚¿ãƒ–ã§ERå›³ã‚’ç¢ºèª
2. å¿…è¦ã«å¿œã˜ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚„ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿®æ­£ãƒ»è¿½åŠ 
3. ç”»é¢è¨­è¨ˆæ›¸ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèª
"""
        
        return supplement
    
    async def _generate_fallback_data(
        self, 
        prompt: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿"""
        
        fallback_mermaid = """erDiagram
    USER {
        string id PK
        string name
        string email
        datetime created_at
        datetime updated_at
    }
    
    PROJECT {
        string id PK
        string name
        string description
        string owner_id FK
        datetime created_at
        datetime updated_at
    }
    
    DOCUMENT {
        string id PK
        string project_id FK
        string name
        string type
        json content
        datetime created_at
        datetime updated_at
    }
    
    USER ||--o{ PROJECT : owns
    PROJECT ||--o{ DOCUMENT : contains"""
        
        fallback_supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ç”Ÿæˆæ–¹å¼**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆAIç”Ÿæˆå¤±æ•—ï¼‰

### âš ï¸ æ³¨æ„
AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. **APIè¨­å®š**: ç’°å¢ƒå¤‰æ•°ã§AIã‚µãƒ¼ãƒ“ã‚¹ã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹
2. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒæ­£å¸¸ã‹
3. **ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³**: AI APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹

### åŸºæœ¬ãƒ¢ãƒ‡ãƒ«èª¬æ˜
- **USER**: ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨è€…
- **PROJECT**: è¨­è¨ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  
- **DOCUMENT**: è¨­è¨ˆæ›¸

AIç”Ÿæˆã®å¾©æ—§å¾Œã€å†åº¦ç”Ÿæˆè¦æ±‚ã‚’é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        return {
            "mermaidCode": fallback_mermaid,
            "supplement": fallback_supplement,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "fallback",
                "project_context": project_context,
                "references": references or [],
                "server_version": "0.1.0",
                "generation_type": "fallback_mermaid",
                "ai_provider": "none"
            }
        }

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
ai_service = AIService()