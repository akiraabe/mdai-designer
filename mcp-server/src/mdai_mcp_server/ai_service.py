# src/mdai_mcp_server/ai_service.py
"""
AI Service for MCP Server
WebUIã®aiServiceã¨åŒç­‰ã®æ©Ÿèƒ½ã‚’MCPã‚µãƒ¼ãƒãƒ¼å´ã§æä¾›
"""

import os
import json
from typing import Dict, Any, Optional
from datetime import datetime
import re
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# AI APIs
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import boto3
    from botocore.exceptions import ClientError
    BEDROCK_AVAILABLE = True
except ImportError:
    BEDROCK_AVAILABLE = False

class AIService:
    """AIç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIè¨­å®šã‚’èª­ã¿è¾¼ã¿
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        self.aws_region = os.getenv('AWS_REGION', 'us-west-2')
        
        # å„ªå…ˆåº¦é †ã§AIã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­å®š
        self.ai_providers = []
        
        if BEDROCK_AVAILABLE and self.aws_access_key:
            self.ai_providers.append('bedrock')
        
        if OPENAI_AVAILABLE and self.openai_api_key:
            self.ai_providers.append('openai')
        
        print(f"ğŸ¤– AI Service initialized with providers: {self.ai_providers}")
        print(f"ğŸ”§ Debug info:")
        print(f"   OpenAI available: {OPENAI_AVAILABLE}")
        print(f"   Bedrock available: {BEDROCK_AVAILABLE}")
        print(f"   OpenAI key set: {'Yes' if self.openai_api_key else 'No'}")
        print(f"   AWS key set: {'Yes' if self.aws_access_key else 'No'}")
    
    async def generate_data_model(
        self, 
        prompt: str, 
        project_context: Optional[Dict] = None,
        references: Optional[list] = None,
        current_mermaid_code: str = ""
    ) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆWebUIã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ï¼‰
        """
        
        print(f"ğŸ¯ AI Data Model Generation Request:")
        print(f"   Prompt: {prompt[:100]}...")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        print(f"   Current Mermaid: {'ã‚ã‚Š' if current_mermaid_code else 'æœªè¨­å®š'}")
        
        # è©³ç´°ãªMermaidãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆWebUIã‹ã‚‰ç§»æ¤ï¼‰
        mermaid_prompt = f"""
ã€çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ã€‘ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸å°‚ç”¨ã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã‚’å¿…ãšMermaid ERå›³ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚

æŒ‡ç¤º: {prompt}

ã€é‡è¦ãªè§£é‡ˆæŒ‡é‡ã€‘:
ã©ã‚“ãªæŒ‡ç¤ºã§ã‚‚ï¼ˆç”»é¢ã€UIã€æ©Ÿèƒ½ãªã©ã®å˜èªãŒã‚ã£ã¦ã‚‚ï¼‰ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ERå›³ã§è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
- ã€Œç”»é¢ã‚’ä½œã£ã¦ã€â†’ ãã®ç”»é¢ã§æ‰±ã†ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã€â†’ Userã€Sessionç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œæ³¨æ–‡ã‚·ã‚¹ãƒ†ãƒ ã€â†’ Orderã€OrderItemã€Productç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œç®¡ç†æ©Ÿèƒ½ã€â†’ ç®¡ç†ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- Mermaid ERå›³: {('ã‚ã‚Šï¼ˆè¿½åŠ ãƒ»ä¿®æ­£ï¼‰' if current_mermaid_code else 'æœªè¨­å®šï¼ˆæ–°è¦ä½œæˆï¼‰')}
- å‚ç…§è¨­è¨ˆæ›¸: {', '.join(references) if references else 'ãªã—'}

ã€å¿…é ˆã€‘erDiagramã§å§‹ã¾ã‚‹Mermaidè¨˜æ³•ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ï¼šMermaidè¨˜æ³•æ³¨æ„äº‹é …ã€‘
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã«ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆï¼ˆ`ï¼‰ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã¯è‹±æ•°å­—ã®ã¿ã§è¨˜è¿°ã—ã¦ãã ã•ã„
- SQLã®äºˆç´„èªã§ã‚‚Mermaidã§ã¯ãã®ã¾ã¾è¨˜è¿°ã—ã¦ãã ã•ã„
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚­ãƒ¼æŒ‡å®šã¯ã€ŒPKã€ã¾ãŸã¯ã€ŒFKã€ã®ã¿ï¼ˆã€ŒPK FKã€ã¯ä¸æ­£ï¼‰
- è¤‡åˆä¸»ã‚­ãƒ¼ã®å ´åˆã¯è¤‡æ•°ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãã‚Œãã‚Œã€ŒPKã€ã‚’æŒ‡å®š

ä¾‹:
erDiagram
    User {{
        int id PK
        string name
        string email
        datetime created_at
    }}
    Order {{
        int id PK
        int user_id FK
        decimal amount
        datetime order_date
    }}
    ProductCategory {{
        int product_id PK
        int category_id PK
    }}
    User ||--o{{ Order : "has many"
        """
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = await self._generate_with_ai(mermaid_prompt)
            
            # Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            mermaid_code = self._extract_mermaid_code(ai_response)
            
            if not mermaid_code:
                raise ValueError("Mermaidã‚³ãƒ¼ãƒ‰ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ
            supplement = self._generate_supplement(
                prompt, 
                mermaid_code, 
                project_context, 
                references
            )
            
            result = {
                "mermaidCode": mermaid_code,
                "supplement": supplement,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "prompt_used": prompt,
                    "mode": "ai_generated",
                    "project_context": project_context,
                    "references": references or [],
                    "server_version": "0.1.0",
                    "generation_type": "dynamic_ai_mermaid",
                    "ai_provider": self.ai_providers[0] if self.ai_providers else "none"
                }
            }
            
            print(f"âœ… AI Data Model Generated:")
            mermaid_lines = len(mermaid_code.split('\n'))
            print(f"   Mermaid lines: {mermaid_lines}")
            print(f"   Supplement chars: {len(supplement)}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI Generation Error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            return await self._generate_fallback_data(prompt, project_context, references)
    
    async def _generate_with_ai(self, prompt: str) -> str:
        """AI APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ç”Ÿæˆ"""
        
        # Bedrockã‚’å„ªå…ˆ
        if 'bedrock' in self.ai_providers:
            try:
                return await self._generate_with_bedrock(prompt)
            except Exception as e:
                print(f"âš ï¸ Bedrock generation failed: {e}")
        
        # OpenAIã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if 'openai' in self.ai_providers:
            try:
                return await self._generate_with_openai(prompt)
            except Exception as e:
                print(f"âš ï¸ OpenAI generation failed: {e}")
        
        raise ValueError("No AI providers available")
    
    async def _generate_with_bedrock(self, prompt: str) -> str:
        """AWS Bedrock ClaudeçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        bedrock = boto3.client(
            'bedrock-runtime',
            region_name=self.aws_region,
            aws_access_key_id=self.aws_access_key,
            aws_secret_access_key=self.aws_secret_key
        )
        
        body = json.dumps({
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 4000,
            "temperature": 0.7,
            "anthropic_version": "bedrock-2023-05-31"
        })
        
        response = bedrock.invoke_model(
            modelId="anthropic.claude-3-sonnet-20240229-v1:0",
            contentType="application/json",
            accept="application/json",
            body=body
        )
        
        response_body = json.loads(response['body'].read())
        return response_body['content'][0]['text']
    
    async def _generate_with_openai(self, prompt: str) -> str:
        """OpenAI GPTçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        print(f"ğŸ”µ OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹...")
        print(f"   Model: gpt-4.1")
        print(f"   API Key: {'è¨­å®šæ¸ˆã¿' if self.openai_api_key else 'æœªè¨­å®š'}")
        
        try:
            client = openai.OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model="gpt-4.1",  # ã‚³ã‚¹ãƒˆãƒ»ç²¾åº¦ãƒ»é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹æœ€é©
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.7
            )
            
            print(f"âœ… OpenAI APIæˆåŠŸ: {len(response.choices[0].message.content)}æ–‡å­—")
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ OpenAI APIå¤±æ•—: {type(e).__name__}: {str(e)}")
            raise
    
    def _extract_mermaid_code(self, ai_response: str) -> str:
        """AIå¿œç­”ã‹ã‚‰Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        mermaid_match = re.search(r'```(?:mermaid)?\s*(erDiagram[\s\S]*?)```', ai_response, re.IGNORECASE)
        if mermaid_match:
            mermaid_code = mermaid_match.group(1).strip()
        else:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãªã—ã®å ´åˆã€erDiagramã‹ã‚‰æŠ½å‡º
            mermaid_match = re.search(r'(erDiagram[\s\S]*)', ai_response, re.IGNORECASE)
            if mermaid_match:
                mermaid_code = mermaid_match.group(1).strip()
            else:
                return ""
        
        # Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®å¾Œå‡¦ç†
        mermaid_code = self._fix_mermaid_syntax(mermaid_code)
        return mermaid_code
    
    def _fix_mermaid_syntax(self, mermaid_code: str) -> str:
        """Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£"""
        
        print(f"ğŸ”§ Mermaidè¨˜æ³•ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£ä¸­...")
        
        # ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»ï¼ˆæœ€ã‚‚é‡è¦ï¼‰
        fixed_code = re.sub(r'`([^`]+)`', r'\1', mermaid_code)
        
        # ä¸æ­£ãªæ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
        if '`' in fixed_code:
            print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»: {fixed_code.count('`')}å€‹")
            fixed_code = fixed_code.replace('`', '')
        
        # ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£ï¼ˆé‡è¦ï¼‰
        pk_fk_count = len(re.findall(r'\s+PK\s+FK\s*', fixed_code))
        if pk_fk_count > 0:
            print(f"âš ï¸ ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {pk_fk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+PK\s+FK\s*', ' PK', fixed_code)
        
        # ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£
        fk_pk_count = len(re.findall(r'\s+FK\s+PK\s*', fixed_code))
        if fk_pk_count > 0:
            print(f"âš ï¸ ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {fk_pk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+FK\s+PK\s*', ' PK', fixed_code)
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®æ¤œè¨¼ï¼ˆè‹±æ•°å­—ã®ã¿ï¼‰
        entity_names = re.findall(r'^\s*([A-Za-z_][A-Za-z0-9_]*)\s*\{', fixed_code, re.MULTILINE)
        print(f"âœ… æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {', '.join(entity_names)}")
        
        return fixed_code
    
    def _generate_supplement(
        self, 
        prompt: str, 
        mermaid_code: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> str:
        """è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ"""
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ã‚’è¨ˆç®—
        entities = re.findall(r'(\w+)\s*\{', mermaid_code)
        relations = re.findall(r'\|\|--[o{].*?:', mermaid_code)
        
        supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- **ç”Ÿæˆæ–¹å¼**: AIå‹•çš„ç”Ÿæˆï¼ˆMCP Serverï¼‰

### ãƒ¢ãƒ‡ãƒ«æ¦‚è¦
{prompt}ã®è¦æ±‚ã«åŸºã¥ã„ã¦è¨­è¨ˆã•ã‚ŒãŸERå›³ã§ã™ã€‚

#### è¨­è¨ˆçµ±è¨ˆ
- **ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°**: {len(entities)}å€‹
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°**: {len(relations)}å€‹
- **æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£**: {', '.join(entities) if entities else 'ãªã—'}

#### ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´
ã“ã®ERå›³ã¯ä»¥ä¸‹ã®è¨­è¨ˆåŸå‰‡ã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼š
- **æ­£è¦åŒ–**: ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã‚’é¿ã‘ã€æ•´åˆæ€§ã‚’ä¿ã¤è¨­è¨ˆ
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é©åˆ‡ãªé–¢ä¿‚å®šç¾©
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å°†æ¥ã®æ‹¡å¼µã‚’è€ƒæ…®ã—ãŸæŸ”è»Ÿãªæ§‹é€ 

### ğŸ¤– AIç”Ÿæˆè©³ç´°
- **ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³**: MCP Server AI Integration
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–**: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç‰¹åŒ–å‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
- **å“è³ªä¿è¨¼**: Mermaidè¨˜æ³•ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯æ¸ˆã¿

### å‚ç…§æƒ…å ±
{f"å‚ç…§ã•ã‚ŒãŸè¨­è¨ˆæ›¸: {', '.join(references)}" if references else "å‚ç…§è¨­è¨ˆæ›¸: ãªã—"}

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ã€Œãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã€ã‚¿ãƒ–ã§ERå›³ã‚’ç¢ºèª
2. å¿…è¦ã«å¿œã˜ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚„ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿®æ­£ãƒ»è¿½åŠ 
3. ç”»é¢è¨­è¨ˆæ›¸ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèª
"""
        
        return supplement
    
    async def generate_design_draft(
        self,
        prompt: str,
        context: Dict[str, Any],
        target_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆï¼ˆWebUIã®aiServiceã¨åŒç­‰æ©Ÿèƒ½ï¼‰
        """
        
        print(f"ğŸ¯ AI Design Draft Generation Request:")
        print(f"   Prompt: {prompt[:100]}...")
        print(f"   Target type: {target_type or 'auto-detect'}")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã®æ¨å®š
        if not target_type:
            target_type = self._infer_target_type(prompt)
        
        # WebUIãŒãƒ–ãƒ©ãƒ³ã‚¯ã‹ã©ã†ã‹ã®åˆ¤å®š
        is_blank = self._is_webui_blank(context)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = self._create_system_prompt(context, target_type, is_blank)
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = await self._generate_with_ai(system_prompt + "\n\n" + prompt)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = self._parse_ai_response(ai_response, prompt, target_type)
            
            result["metadata"] = {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "ai_generated",
                "target_type": target_type,
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "design_draft",
                "ai_provider": self.ai_providers[0] if self.ai_providers else "none"
            }
            
            print(f"âœ… AI Design Draft Generated:")
            if 'spreadsheetData' in result:
                print(f"   Spreadsheet rows: {len(result['spreadsheetData'])}")
            if 'markdownContent' in result:
                print(f"   Markdown chars: {len(result['markdownContent'])}")
            print(f"   Target type: {target_type}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI Design Draft Generation Error: {e}")
            return await self._generate_fallback_design_draft(prompt, target_type, project_context)
    
    async def generate_chat_response(
        self,
        user_message: str,
        context: Dict[str, Any],
        document_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """
        ãƒãƒ£ãƒƒãƒˆå¿œç­”ç”Ÿæˆï¼ˆWebUIã®aiServiceã¨åŒç­‰æ©Ÿèƒ½ï¼‰
        """
        
        print(f"ğŸ¯ AI Chat Response Generation Request:")
        print(f"   Message: {user_message[:100]}...")
        print(f"   Document type: {document_type or 'general'}")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        # ãƒãƒ£ãƒƒãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = self._create_chat_system_prompt(context, document_type)
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            response = await self._generate_with_ai(system_prompt + "\n\n" + user_message)
            
            print(f"âœ… AI Chat Response Generated:")
            print(f"   Response chars: {len(response)}")
            print(f"   AI Provider: {self.ai_providers[0] if self.ai_providers else 'none'}")
            
            return response
            
        except Exception as e:
            print(f"âŒ AI Chat Response Generation Error: {e}")
            return f"""ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆå¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

**ã‚¨ãƒ©ãƒ¼è©³ç´°**:
- ç™ºç”Ÿæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ã‚¨ãƒ©ãƒ¼å†…å®¹: {str(e)}
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}

**å¯¾å‡¦æ–¹æ³•**:
1. AI APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„

ã”ä¸ä¾¿ã‚’ãŠã‹ã‘ã—ã¦ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚"""
    
    def _infer_target_type(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰å¯¾è±¡ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š"""
        prompt_lower = prompt.lower()
        
        if any(keyword in prompt_lower for keyword in ['ç”»é¢', 'ui', 'ux', 'ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ', 'ãƒšãƒ¼ã‚¸']):
            return 'screen'
        elif any(keyword in prompt_lower for keyword in ['ãƒ‡ãƒ¼ã‚¿', 'ãƒ¢ãƒ‡ãƒ«', 'ãƒ†ãƒ¼ãƒ–ãƒ«', 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£', 'er']):
            return 'model'
        elif any(keyword in prompt_lower for keyword in ['api', 'endpoint', 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆ', 'ãƒ¬ã‚¹ãƒãƒ³ã‚¹']):
            return 'api'
        else:
            return 'screen'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _is_webui_blank(self, context: Dict[str, Any]) -> bool:
        """WebUIãŒãƒ–ãƒ©ãƒ³ã‚¯ã‹ã©ã†ã‹ã®åˆ¤å®š"""
        if not context:
            return True
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        spreadsheet_data = context.get('spreadsheetData', [])
        if spreadsheet_data and len(spreadsheet_data) > 0:
            # ç©ºã§ãªã„é …ç›®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for row in spreadsheet_data:
                if row.get('é …ç›®å') and row.get('é …ç›®å').strip():
                    return False
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç¢ºèª
        markdown_content = context.get('markdownContent', '')
        if markdown_content and markdown_content.strip():
            return False
        
        return True
    
    def _create_system_prompt(self, context: Dict[str, Any], target_type: str, is_blank: bool) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        if target_type == 'screen':
            return f"""ã‚ãªãŸã¯ç”»é¢è¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€ç”»é¢è¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "é …ç›®å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# ç”»é¢è¨­è¨ˆæ›¸\\n\\n## è¡¨ç¤ºæ¡ä»¶\\n..."
}}

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿: {len(context.get('spreadsheetData', []))}è¡Œ
- Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {len(context.get('markdownContent', ''))}æ–‡å­—

ç”»é¢è¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- è¡¨ç¤ºæ¡ä»¶
- é …ç›®å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ï¼‰
- è£œè¶³èª¬æ˜"""
        
        elif target_type == 'api':
            return f"""ã‚ãªãŸã¯APIè¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€APIè¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# APIè¨­è¨ˆæ›¸\\n\\n## ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\\n..."
}}

APIè¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä»•æ§˜
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        
        else:  # model
            return f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸\\n\\n## ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å®šç¾©\\n..."
}}

ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å®šç¾©
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®šç¾©
- åˆ¶ç´„æ¡ä»¶"""
    
    def _create_chat_system_prompt(self, context: Dict[str, Any], document_type: Optional[str]) -> str:
        """ãƒãƒ£ãƒƒãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        doc_type_name = {
            'screen': 'ç”»é¢è¨­è¨ˆæ›¸',
            'model': 'ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸',
            'api': 'APIè¨­è¨ˆæ›¸'
        }.get(document_type, 'è¨­è¨ˆæ›¸')
        
        return f"""ã‚ãªãŸã¯{doc_type_name}ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ç¾åœ¨ã®è¨­è¨ˆæ›¸ã®å†…å®¹ã‚’è¸ã¾ãˆã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿: {len(context.get('spreadsheetData', []))}è¡Œ
- Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {len(context.get('markdownContent', ''))}æ–‡å­—
- Mermaidã‚³ãƒ¼ãƒ‰: {len(context.get('mermaidCode', ''))}æ–‡å­—

å›ç­”æ™‚ã®æ³¨æ„ç‚¹:
- æŠ€è¡“çš„ã«æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›
- å…·ä½“çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
- ç¾åœ¨ã®è¨­è¨ˆæ›¸ã¨ã®æ•´åˆæ€§ã‚’è€ƒæ…®
- æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜"""
    
    def _parse_ai_response(self, ai_response: str, prompt: str, target_type: str) -> Dict[str, Any]:
        """AIå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
        
        # JSONå½¢å¼ã®å¿œç­”ã‚’æŠ½å‡º
        json_match = re.search(r'\{[\s\S]*\}', ai_response)
        if json_match:
            try:
                parsed_data = json.loads(json_match.group(0))
                if 'spreadsheetData' in parsed_data and 'markdownContent' in parsed_data:
                    return parsed_data
            except json.JSONDecodeError:
                pass
        
        # JSONæŠ½å‡ºå¤±æ•—æ™‚ã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”Ÿæˆ
        return self._extract_from_text(ai_response, target_type)
    
    def _extract_from_text(self, text: str, target_type: str) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨­è¨ˆæ›¸ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        
        # åŸºæœ¬çš„ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        if target_type == 'screen':
            spreadsheet_data = [
                {"é …ç›®å": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è­˜åˆ¥ã™ã‚‹ID"},
                {"é …ç›®å": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "è¡¨ç¤ºç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å"},
                {"é …ç›®å": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãƒ‡ãƒ¼ã‚¿å‹": "email", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ­ã‚°ã‚¤ãƒ³ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"}
            ]
        elif target_type == 'api':
            spreadsheet_data = [
                {"é …ç›®å": "user_id", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"},
                {"é …ç›®å": "name", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å"},
                {"é …ç›®å": "email", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"}
            ]
        else:  # model
            spreadsheet_data = [
                {"é …ç›®å": "id", "ãƒ‡ãƒ¼ã‚¿å‹": "bigint", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼"},
                {"é …ç›®å": "name", "ãƒ‡ãƒ¼ã‚¿å‹": "varchar(255)", "å¿…é ˆ": "â—‹", "èª¬æ˜": "åå‰"},
                {"é …ç›®å": "created_at", "ãƒ‡ãƒ¼ã‚¿å‹": "timestamp", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ä½œæˆæ—¥æ™‚"}
            ]
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
        markdown_content = f"""# {target_type.title()}è¨­è¨ˆæ›¸

## æ¦‚è¦
{text[:200]}...

## ç”Ÿæˆæƒ…å ±
- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ç”Ÿæˆæ–¹å¼: AIå‹•çš„ç”Ÿæˆï¼ˆMCP Serverï¼‰

## è©³ç´°
AIç”Ÿæˆã«ã‚ˆã‚‹åŸºæœ¬çš„ãªè¨­è¨ˆæ›¸ã§ã™ã€‚å¿…è¦ã«å¿œã˜ã¦é …ç›®ã‚’è¿½åŠ ãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
"""
        
        return {
            "spreadsheetData": spreadsheet_data,
            "markdownContent": markdown_content
        }
    
    async def _generate_fallback_design_draft(
        self,
        prompt: str,
        target_type: str,
        project_context: Optional[Dict]
    ) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆ"""
        
        spreadsheet_data = [
            {"é …ç›®å": "ã‚¨ãƒ©ãƒ¼", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": f"ç”Ÿæˆã‚¨ãƒ©ãƒ¼: AI APIã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ"}
        ]
        
        markdown_content = f"""# {target_type.title()}è¨­è¨ˆæ›¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

## âš ï¸ ç”Ÿæˆã‚¨ãƒ©ãƒ¼
AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªè¨­è¨ˆæ›¸ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚

### ã‚¨ãƒ©ãƒ¼è©³ç´°
- ç™ºç”Ÿæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}
- å¯¾è±¡ã‚¿ã‚¤ãƒ—: {target_type}

### å¯¾å‡¦æ–¹æ³•
1. AI APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„

AIç”Ÿæˆã®å¾©æ—§å¾Œã€å†åº¦ç”Ÿæˆè¦æ±‚ã‚’é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        return {
            "spreadsheetData": spreadsheet_data,
            "markdownContent": markdown_content,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "fallback",
                "target_type": target_type,
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "fallback_design_draft",
                "ai_provider": "none"
            }
        }
    
    async def _generate_fallback_data(
        self, 
        prompt: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿"""
        
        fallback_mermaid = """erDiagram
    USER {
        string id PK
        string name
        string email
        datetime created_at
        datetime updated_at
    }
    
    PROJECT {
        string id PK
        string name
        string description
        string owner_id FK
        datetime created_at
        datetime updated_at
    }
    
    DOCUMENT {
        string id PK
        string project_id FK
        string name
        string type
        json content
        datetime created_at
        datetime updated_at
    }
    
    USER ||--o{ PROJECT : owns
    PROJECT ||--o{ DOCUMENT : contains"""
        
        fallback_supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ç”Ÿæˆæ–¹å¼**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆAIç”Ÿæˆå¤±æ•—ï¼‰

### âš ï¸ æ³¨æ„
AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. **APIè¨­å®š**: ç’°å¢ƒå¤‰æ•°ã§AIã‚µãƒ¼ãƒ“ã‚¹ã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹
2. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒæ­£å¸¸ã‹
3. **ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³**: AI APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹

### åŸºæœ¬ãƒ¢ãƒ‡ãƒ«èª¬æ˜
- **USER**: ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨è€…
- **PROJECT**: è¨­è¨ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  
- **DOCUMENT**: è¨­è¨ˆæ›¸

AIç”Ÿæˆã®å¾©æ—§å¾Œã€å†åº¦ç”Ÿæˆè¦æ±‚ã‚’é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        return {
            "mermaidCode": fallback_mermaid,
            "supplement": fallback_supplement,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "fallback",
                "project_context": project_context,
                "references": references or [],
                "server_version": "0.1.0",
                "generation_type": "fallback_mermaid",
                "ai_provider": "none"
            }
        }

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
ai_service = AIService()