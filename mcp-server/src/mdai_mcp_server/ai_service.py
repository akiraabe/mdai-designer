# src/mdai_mcp_server/ai_service.py
"""
AI Service for MCP Server
WebUIã®aiServiceã¨åŒç­‰ã®æ©Ÿèƒ½ã‚’MCPã‚µãƒ¼ãƒãƒ¼å´ã§æä¾›
"""

import os
import json
from typing import Dict, Any, Optional
from datetime import datetime
import re
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# AI APIs
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import boto3
    from botocore.exceptions import ClientError
    BEDROCK_AVAILABLE = True
except ImportError:
    BEDROCK_AVAILABLE = False

class AIService:
    """AIç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIè¨­å®šã‚’èª­ã¿è¾¼ã¿
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        self.aws_region = os.getenv('AWS_REGION', 'us-west-2')
        
        # å„ªå…ˆåº¦é †ã§AIã‚µãƒ¼ãƒ“ã‚¹ã‚’è¨­å®š
        self.ai_providers = []
        
        if BEDROCK_AVAILABLE and self.aws_access_key:
            self.ai_providers.append('bedrock')
        
        if OPENAI_AVAILABLE and self.openai_api_key:
            self.ai_providers.append('openai')
        
        print(f"ğŸ¤– AI Service initialized with providers: {self.ai_providers}")
        print(f"ğŸ”§ Debug info:")
        print(f"   OpenAI available: {OPENAI_AVAILABLE}")
        print(f"   Bedrock available: {BEDROCK_AVAILABLE}")
        print(f"   OpenAI key set: {'Yes' if self.openai_api_key else 'No'}")
        print(f"   AWS key set: {'Yes' if self.aws_access_key else 'No'}")
    
    async def generate_data_model(
        self, 
        prompt: str, 
        project_context: Optional[Dict] = None,
        references: Optional[list] = None,
        current_mermaid_code: str = ""
    ) -> Dict[str, Any]:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆWebUIã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ï¼‰
        """
        
        print(f"ğŸ¯ AI Data Model Generation Request:")
        print(f"   Prompt: {prompt[:100]}...")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        print(f"   Current Mermaid: {'ã‚ã‚Š' if current_mermaid_code else 'æœªè¨­å®š'}")
        
        # è©³ç´°ãªMermaidãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ï¼ˆWebUIã‹ã‚‰ç§»æ¤ï¼‰
        mermaid_prompt = f"""
ã€çµ¶å¯¾ãƒ«ãƒ¼ãƒ«ã€‘ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸å°‚ç”¨ã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã‚’å¿…ãšMermaid ERå›³ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚

æŒ‡ç¤º: {prompt}

ã€é‡è¦ãªè§£é‡ˆæŒ‡é‡ã€‘:
ã©ã‚“ãªæŒ‡ç¤ºã§ã‚‚ï¼ˆç”»é¢ã€UIã€æ©Ÿèƒ½ãªã©ã®å˜èªãŒã‚ã£ã¦ã‚‚ï¼‰ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ERå›³ã§è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
- ã€Œç”»é¢ã‚’ä½œã£ã¦ã€â†’ ãã®ç”»é¢ã§æ‰±ã†ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œãƒ­ã‚°ã‚¤ãƒ³æ©Ÿèƒ½ã€â†’ Userã€Sessionç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œæ³¨æ–‡ã‚·ã‚¹ãƒ†ãƒ ã€â†’ Orderã€OrderItemã€Productç­‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£è¨­è¨ˆ
- ã€Œç®¡ç†æ©Ÿèƒ½ã€â†’ ç®¡ç†ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- Mermaid ERå›³: {('ã‚ã‚Šï¼ˆè¿½åŠ ãƒ»ä¿®æ­£ï¼‰' if current_mermaid_code else 'æœªè¨­å®šï¼ˆæ–°è¦ä½œæˆï¼‰')}
- å‚ç…§è¨­è¨ˆæ›¸: {', '.join(references) if references else 'ãªã—'}

ã€å¿…é ˆã€‘erDiagramã§å§‹ã¾ã‚‹Mermaidè¨˜æ³•ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢ä¿‚ã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ï¼šMermaidè¨˜æ³•æ³¨æ„äº‹é …ã€‘
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã«ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆï¼ˆ`ï¼‰ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã¯è‹±æ•°å­—ã®ã¿ã§è¨˜è¿°ã—ã¦ãã ã•ã„
- SQLã®äºˆç´„èªã§ã‚‚Mermaidã§ã¯ãã®ã¾ã¾è¨˜è¿°ã—ã¦ãã ã•ã„
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚­ãƒ¼æŒ‡å®šã¯ã€ŒPKã€ã¾ãŸã¯ã€ŒFKã€ã®ã¿ï¼ˆã€ŒPK FKã€ã¯ä¸æ­£ï¼‰
- è¤‡åˆä¸»ã‚­ãƒ¼ã®å ´åˆã¯è¤‡æ•°ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãã‚Œãã‚Œã€ŒPKã€ã‚’æŒ‡å®š

ä¾‹:
erDiagram
    User {{
        int id PK
        string name
        string email
        datetime created_at
    }}
    Order {{
        int id PK
        int user_id FK
        decimal amount
        datetime order_date
    }}
    ProductCategory {{
        int product_id PK
        int category_id PK
    }}
    User ||--o{{ Order : "has many"
        """
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = await self._generate_with_ai(mermaid_prompt)
            
            # Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            mermaid_code = self._extract_mermaid_code(ai_response)
            
            if not mermaid_code:
                raise ValueError("Mermaidã‚³ãƒ¼ãƒ‰ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ
            supplement = self._generate_supplement(
                prompt, 
                mermaid_code, 
                project_context, 
                references
            )
            
            result = {
                "mermaidCode": mermaid_code,
                "supplement": supplement,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "prompt_used": prompt,
                    "mode": "ai_generated",
                    "project_context": project_context,
                    "references": references or [],
                    "server_version": "0.1.0",
                    "generation_type": "dynamic_ai_mermaid",
                    "ai_provider": self.ai_providers[0] if self.ai_providers else "none"
                }
            }
            
            print(f"âœ… AI Data Model Generated:")
            mermaid_lines = len(mermaid_code.split('\n'))
            print(f"   Mermaid lines: {mermaid_lines}")
            print(f"   Supplement chars: {len(supplement)}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI Generation Error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å›ºå®šãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            return await self._generate_fallback_data(prompt, project_context, references)
    
    async def _generate_with_ai(self, prompt: str) -> str:
        """AI APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ç”Ÿæˆ"""
        
        # Bedrockã‚’å„ªå…ˆ
        if 'bedrock' in self.ai_providers:
            try:
                return await self._generate_with_bedrock(prompt)
            except Exception as e:
                print(f"âš ï¸ Bedrock generation failed: {e}")
        
        # OpenAIã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if 'openai' in self.ai_providers:
            try:
                return await self._generate_with_openai(prompt)
            except Exception as e:
                print(f"âš ï¸ OpenAI generation failed: {e}")
        
        raise ValueError("No AI providers available")
    
    async def _generate_with_bedrock(self, prompt: str) -> str:
        """AWS Bedrock ClaudeçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        bedrock = boto3.client(
            'bedrock-runtime',
            region_name=self.aws_region,
            aws_access_key_id=self.aws_access_key,
            aws_secret_access_key=self.aws_secret_key
        )
        
        body = json.dumps({
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 4000,
            "temperature": 0.7,
            "anthropic_version": "bedrock-2023-05-31"
        })
        
        response = bedrock.invoke_model(
            modelId="anthropic.claude-3-sonnet-20240229-v1:0",
            contentType="application/json",
            accept="application/json",
            body=body
        )
        
        response_body = json.loads(response['body'].read())
        return response_body['content'][0]['text']
    
    async def _generate_with_openai(self, prompt: str) -> str:
        """OpenAI GPTçµŒç”±ã§ã®ç”Ÿæˆ"""
        
        print(f"ğŸ”µ OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹...")
        print(f"   Model: gpt-4.1")
        print(f"   API Key: {'è¨­å®šæ¸ˆã¿' if self.openai_api_key else 'æœªè¨­å®š'}")
        
        try:
            client = openai.OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model="gpt-4.1",  # ã‚³ã‚¹ãƒˆãƒ»ç²¾åº¦ãƒ»é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹æœ€é©
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.7
            )
            
            print(f"âœ… OpenAI APIæˆåŠŸ: {len(response.choices[0].message.content)}æ–‡å­—")
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âŒ OpenAI APIå¤±æ•—: {type(e).__name__}: {str(e)}")
            raise
    
    def _extract_mermaid_code(self, ai_response: str) -> str:
        """AIå¿œç­”ã‹ã‚‰Mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®mermaidã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        mermaid_match = re.search(r'```(?:mermaid)?\s*(erDiagram[\s\S]*?)```', ai_response, re.IGNORECASE)
        if mermaid_match:
            mermaid_code = mermaid_match.group(1).strip()
        else:
            # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãªã—ã®å ´åˆã€erDiagramã‹ã‚‰æŠ½å‡º
            mermaid_match = re.search(r'(erDiagram[\s\S]*)', ai_response, re.IGNORECASE)
            if mermaid_match:
                mermaid_code = mermaid_match.group(1).strip()
            else:
                return ""
        
        # Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®å¾Œå‡¦ç†
        mermaid_code = self._fix_mermaid_syntax(mermaid_code)
        return mermaid_code
    
    def _fix_mermaid_syntax(self, mermaid_code: str) -> str:
        """Mermaidæ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£"""
        
        print(f"ğŸ”§ Mermaidè¨˜æ³•ãƒã‚§ãƒƒã‚¯ãƒ»ä¿®æ­£ä¸­...")
        
        # ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»ï¼ˆæœ€ã‚‚é‡è¦ï¼‰
        fixed_code = re.sub(r'`([^`]+)`', r'\1', mermaid_code)
        
        # ä¸æ­£ãªæ–‡å­—ã‚’ãƒã‚§ãƒƒã‚¯
        if '`' in fixed_code:
            print(f"âš ï¸ ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’é™¤å»: {fixed_code.count('`')}å€‹")
            fixed_code = fixed_code.replace('`', '')
        
        # ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£ï¼ˆé‡è¦ï¼‰
        pk_fk_count = len(re.findall(r'\s+PK\s+FK\s*', fixed_code))
        if pk_fk_count > 0:
            print(f"âš ï¸ ã€ŒPK FKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {pk_fk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+PK\s+FK\s*', ' PK', fixed_code)
        
        # ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£
        fk_pk_count = len(re.findall(r'\s+FK\s+PK\s*', fixed_code))
        if fk_pk_count > 0:
            print(f"âš ï¸ ã€ŒFK PKã€ã‚’ã€ŒPKã€ã«ä¿®æ­£: {fk_pk_count}ç®‡æ‰€")
            fixed_code = re.sub(r'\s+FK\s+PK\s*', ' PK', fixed_code)
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®æ¤œè¨¼ï¼ˆè‹±æ•°å­—ã®ã¿ï¼‰
        entity_names = re.findall(r'^\s*([A-Za-z_][A-Za-z0-9_]*)\s*\{', fixed_code, re.MULTILINE)
        print(f"âœ… æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£: {', '.join(entity_names)}")
        
        return fixed_code
    
    def _generate_supplement(
        self, 
        prompt: str, 
        mermaid_code: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> str:
        """è£œè¶³èª¬æ˜ã‚’ç”Ÿæˆ"""
        
        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°ã‚’è¨ˆç®—
        entities = re.findall(r'(\w+)\s*\{', mermaid_code)
        relations = re.findall(r'\|\|--[o{].*?:', mermaid_code)
        
        supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}
- **ç”Ÿæˆæ–¹å¼**: AIå‹•çš„ç”Ÿæˆï¼ˆMCP Serverï¼‰

### ãƒ¢ãƒ‡ãƒ«æ¦‚è¦
{prompt}ã®è¦æ±‚ã«åŸºã¥ã„ã¦è¨­è¨ˆã•ã‚ŒãŸERå›³ã§ã™ã€‚

#### è¨­è¨ˆçµ±è¨ˆ
- **ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°**: {len(entities)}å€‹
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°**: {len(relations)}å€‹
- **æ¤œå‡ºã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£**: {', '.join(entities) if entities else 'ãªã—'}

#### ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´
ã“ã®ERå›³ã¯ä»¥ä¸‹ã®è¨­è¨ˆåŸå‰‡ã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼š
- **æ­£è¦åŒ–**: ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ã‚’é¿ã‘ã€æ•´åˆæ€§ã‚’ä¿ã¤è¨­è¨ˆ
- **ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£é–“ã®é©åˆ‡ãªé–¢ä¿‚å®šç¾©
- **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å°†æ¥ã®æ‹¡å¼µã‚’è€ƒæ…®ã—ãŸæŸ”è»Ÿãªæ§‹é€ 

### ğŸ¤– AIç”Ÿæˆè©³ç´°
- **ç”Ÿæˆã‚¨ãƒ³ã‚¸ãƒ³**: MCP Server AI Integration
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–**: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç‰¹åŒ–å‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½¿ç”¨
- **å“è³ªä¿è¨¼**: Mermaidè¨˜æ³•ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯æ¸ˆã¿

### å‚ç…§æƒ…å ±
{f"å‚ç…§ã•ã‚ŒãŸè¨­è¨ˆæ›¸: {', '.join(references)}" if references else "å‚ç…§è¨­è¨ˆæ›¸: ãªã—"}

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. ã€Œãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã€ã‚¿ãƒ–ã§ERå›³ã‚’ç¢ºèª
2. å¿…è¦ã«å¿œã˜ã¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚„ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿®æ­£ãƒ»è¿½åŠ 
3. ç”»é¢è¨­è¨ˆæ›¸ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèª
"""
        
        return supplement
    
    async def generate_design_draft(
        self,
        prompt: str,
        context: Dict[str, Any],
        target_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆï¼ˆWebUIã®aiServiceã¨åŒç­‰æ©Ÿèƒ½ï¼‰
        """
        
        print(f"ğŸ¯ AI Design Draft Generation Request:")
        print(f"   Prompt: {prompt[:100]}...")
        print(f"   Target type: {target_type or 'auto-detect'}")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¿ã‚¤ãƒ—ã®æ¨å®š
        if not target_type:
            target_type = self._infer_target_type(prompt)
        
        # WebUIãŒãƒ–ãƒ©ãƒ³ã‚¯ã‹ã©ã†ã‹ã®åˆ¤å®š
        is_blank = self._is_webui_blank(context)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = self._create_system_prompt(context, target_type, is_blank)
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            ai_response = await self._generate_with_ai(system_prompt + "\n\n" + prompt)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
            result = self._parse_ai_response(ai_response, prompt, target_type)
            
            result["metadata"] = {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "ai_generated",
                "target_type": target_type,
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "design_draft",
                "ai_provider": self.ai_providers[0] if self.ai_providers else "none"
            }
            
            print(f"âœ… AI Design Draft Generated:")
            if 'spreadsheetData' in result:
                print(f"   Spreadsheet rows: {len(result['spreadsheetData'])}")
            if 'markdownContent' in result:
                print(f"   Markdown chars: {len(result['markdownContent'])}")
            print(f"   Target type: {target_type}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI Design Draft Generation Error: {e}")
            return await self._generate_fallback_design_draft(prompt, target_type, project_context)
    
    async def generate_chat_response(
        self,
        user_message: str,
        context: Dict[str, Any],
        document_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """
        ãƒãƒ£ãƒƒãƒˆå¿œç­”ç”Ÿæˆï¼ˆWebUIã®aiServiceã¨åŒç­‰æ©Ÿèƒ½ï¼‰
        """
        
        print(f"ğŸ¯ AI Chat Response Generation Request:")
        print(f"   Message: {user_message[:100]}...")
        print(f"   Document type: {document_type or 'general'}")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        # ãƒãƒ£ãƒƒãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        system_prompt = self._create_chat_system_prompt(context, document_type)
        
        try:
            # AIå¿œç­”ã‚’ç”Ÿæˆ
            response = await self._generate_with_ai(system_prompt + "\n\n" + user_message)
            
            print(f"âœ… AI Chat Response Generated:")
            print(f"   Response chars: {len(response)}")
            print(f"   AI Provider: {self.ai_providers[0] if self.ai_providers else 'none'}")
            
            return response
            
        except Exception as e:
            print(f"âŒ AI Chat Response Generation Error: {e}")
            return f"""ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ãƒãƒ£ãƒƒãƒˆå¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚

**ã‚¨ãƒ©ãƒ¼è©³ç´°**:
- ç™ºç”Ÿæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ã‚¨ãƒ©ãƒ¼å†…å®¹: {str(e)}
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}

**å¯¾å‡¦æ–¹æ³•**:
1. AI APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„

ã”ä¸ä¾¿ã‚’ãŠã‹ã‘ã—ã¦ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚"""
    
    def _infer_target_type(self, prompt: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰å¯¾è±¡ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š"""
        prompt_lower = prompt.lower()
        
        if any(keyword in prompt_lower for keyword in ['ç”»é¢', 'ui', 'ux', 'ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ', 'ãƒšãƒ¼ã‚¸']):
            return 'screen'
        elif any(keyword in prompt_lower for keyword in ['ãƒ‡ãƒ¼ã‚¿', 'ãƒ¢ãƒ‡ãƒ«', 'ãƒ†ãƒ¼ãƒ–ãƒ«', 'ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£', 'er']):
            return 'model'
        elif any(keyword in prompt_lower for keyword in ['api', 'endpoint', 'ãƒªã‚¯ã‚¨ã‚¹ãƒˆ', 'ãƒ¬ã‚¹ãƒãƒ³ã‚¹']):
            return 'api'
        else:
            return 'screen'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _is_webui_blank(self, context: Dict[str, Any]) -> bool:
        """WebUIãŒãƒ–ãƒ©ãƒ³ã‚¯ã‹ã©ã†ã‹ã®åˆ¤å®š"""
        if not context:
            return True
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        spreadsheet_data = context.get('spreadsheetData', [])
        if spreadsheet_data and len(spreadsheet_data) > 0:
            # ç©ºã§ãªã„é …ç›®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for row in spreadsheet_data:
                if row.get('é …ç›®å') and row.get('é …ç›®å').strip():
                    return False
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç¢ºèª
        markdown_content = context.get('markdownContent', '')
        if markdown_content and markdown_content.strip():
            return False
        
        return True
    
    def _create_system_prompt(self, context: Dict[str, Any], target_type: str, is_blank: bool) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        if target_type == 'screen':
            return f"""ã‚ãªãŸã¯ç”»é¢è¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€ç”»é¢è¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "é …ç›®å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# ç”»é¢è¨­è¨ˆæ›¸\\n\\n## è¡¨ç¤ºæ¡ä»¶\\n..."
}}

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿: {len(context.get('spreadsheetData', []))}è¡Œ
- Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {len(context.get('markdownContent', ''))}æ–‡å­—

ç”»é¢è¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- è¡¨ç¤ºæ¡ä»¶
- é …ç›®å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ï¼‰
- è£œè¶³èª¬æ˜"""
        
        elif target_type == 'api':
            return f"""ã‚ãªãŸã¯APIè¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€APIè¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# APIè¨­è¨ˆæ›¸\\n\\n## ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ\\n..."
}}

APIè¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä»•æ§˜
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        
        else:  # model
            return f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®è¦æ±‚ã«å¯¾ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{'ã€æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰ã€‘' if is_blank else 'ã€è¿½åŠ ãƒ»ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰ã€‘'}

å‡ºåŠ›å½¢å¼ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
{{
  "spreadsheetData": [
    {{"é …ç›®å": "ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å", "ãƒ‡ãƒ¼ã‚¿å‹": "ãƒ‡ãƒ¼ã‚¿å‹", "å¿…é ˆ": "â—‹/Ã—", "èª¬æ˜": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "markdownContent": "# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸\\n\\n## ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å®šç¾©\\n..."
}}

ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ã¨ã—ã¦å¿…è¦ãªè¦ç´ ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å®šç¾©
- ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ï¼‰
- ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®šç¾©
- åˆ¶ç´„æ¡ä»¶"""
    
    def _create_chat_system_prompt(self, context: Dict[str, Any], document_type: Optional[str]) -> str:
        """ãƒãƒ£ãƒƒãƒˆç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
        
        doc_type_name = {
            'screen': 'ç”»é¢è¨­è¨ˆæ›¸',
            'model': 'ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸',
            'api': 'APIè¨­è¨ˆæ›¸'
        }.get(document_type, 'è¨­è¨ˆæ›¸')
        
        return f"""ã‚ãªãŸã¯{doc_type_name}ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ç¾åœ¨ã®è¨­è¨ˆæ›¸ã®å†…å®¹ã‚’è¸ã¾ãˆã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®è¨­è¨ˆæ›¸çŠ¶æ³:
- ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿: {len(context.get('spreadsheetData', []))}è¡Œ
- Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {len(context.get('markdownContent', ''))}æ–‡å­—
- Mermaidã‚³ãƒ¼ãƒ‰: {len(context.get('mermaidCode', ''))}æ–‡å­—

å›ç­”æ™‚ã®æ³¨æ„ç‚¹:
- æŠ€è¡“çš„ã«æ­£ç¢ºãªæƒ…å ±ã‚’æä¾›
- å…·ä½“çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
- ç¾åœ¨ã®è¨­è¨ˆæ›¸ã¨ã®æ•´åˆæ€§ã‚’è€ƒæ…®
- æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜"""
    
    def _parse_ai_response(self, ai_response: str, prompt: str, target_type: str) -> Dict[str, Any]:
        """AIå¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ï¼ˆWebUI GeneratedDraftå½¢å¼ï¼‰"""
        
        # JSONå½¢å¼ã®å¿œç­”ã‚’æŠ½å‡º
        json_match = re.search(r'\{[\s\S]*\}', ai_response)
        if json_match:
            try:
                parsed_data = json.loads(json_match.group(0))
                if 'spreadsheetData' in parsed_data and 'markdownContent' in parsed_data:
                    # AIç”Ÿæˆã•ã‚ŒãŸJSONã‚’GeneratedDraftå½¢å¼ã«å¤‰æ›
                    return self._convert_ai_json_to_draft(parsed_data, target_type)
            except json.JSONDecodeError:
                pass
        
        # JSONæŠ½å‡ºå¤±æ•—æ™‚ã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”Ÿæˆ
        return self._extract_from_text(ai_response, target_type)
    
    def _convert_ai_json_to_draft(self, ai_data: Dict, target_type: str) -> Dict[str, Any]:
        """AIç”ŸæˆJSONã‚’WebUI GeneratedDraftå½¢å¼ã«å¤‰æ›"""
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›
        spreadsheet_cells = []
        if 'spreadsheetData' in ai_data and ai_data['spreadsheetData']:
            spreadsheet_cells = self._convert_table_to_cells(ai_data['spreadsheetData'])
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ†å‰²
        markdown_content = ai_data.get('markdownContent', '')
        conditions, supplement = self._split_markdown_content(markdown_content)
        
        return {
            "type": "mixed",
            "spreadsheetData": spreadsheet_cells,
            "conditions": conditions or markdown_content,
            "supplement": supplement
        }
    
    def _convert_table_to_cells(self, table_data: list) -> list:
        """è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒ«å½¢å¼ã«å¤‰æ›ï¼ˆWebUI GeneratedDraftäº’æ›ï¼‰"""
        cells = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
        headers = ['é …ç›®å', 'ãƒ‡ãƒ¼ã‚¿å‹', 'å¿…é ˆ', 'èª¬æ˜']
        for col_index, header in enumerate(headers):
            cells.append({
                'r': 0,
                'c': col_index,
                'v': header
            })
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for row_index, row_data in enumerate(table_data):
            data_row = row_index + 1
            cells.extend([
                {'r': data_row, 'c': 0, 'v': row_data.get('é …ç›®å', '')},
                {'r': data_row, 'c': 1, 'v': row_data.get('ãƒ‡ãƒ¼ã‚¿å‹', '')},
                {'r': data_row, 'c': 2, 'v': row_data.get('å¿…é ˆ', '')},
                {'r': data_row, 'c': 3, 'v': row_data.get('èª¬æ˜', '')}
            ])
        
        return cells
    
    def _split_markdown_content(self, markdown_content: str) -> tuple:
        """markdownContentã‚’conditionsã¨supplementã«åˆ†å‰²"""
        lines = markdown_content.split('\n')
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ¥ã«åˆ†é¡
        conditions_lines = []
        supplement_lines = []
        current_section = 'supplement'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        skip_section = False  # é …ç›®å®šç¾©ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—
        
        for i, line in enumerate(lines):
            line_lower = line.lower()
            
            # è¡¨ç¤ºæ¡ä»¶ã«é–¢é€£ã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡º
            if any(keyword in line_lower for keyword in [
                'è¡¨ç¤ºæ¡ä»¶', 'æ¡ä»¶', 'condition', 
                'è¡¨ç¤ºåˆ¶å¾¡', 'ç”»é¢è¡¨ç¤ºæ¡ä»¶', 'è¡¨ç¤ºãƒ«ãƒ¼ãƒ«'
            ]) and line.startswith('#'):
                current_section = 'conditions'
                skip_section = False
                conditions_lines.append(line)
                continue
                
            # é …ç›®å®šç¾©ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã§è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ï¼‰
            elif 'é …ç›®å®šç¾©' in line_lower and line.startswith('#'):
                current_section = 'skip'
                skip_section = True
                continue
                
            # è£œè¶³èª¬æ˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡ºï¼ˆæ˜ç¤ºçš„ãªå ´åˆï¼‰
            elif any(keyword in line_lower for keyword in [
                'è£œè¶³èª¬æ˜', 'è£œè¶³', 'æ³¨æ„', 'å‚™è€ƒ', 'è©³ç´°', 
                'ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸', 'ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ', 'è¨­è¨ˆ', 'ä»•æ§˜'
            ]) and line.startswith('#'):
                current_section = 'supplement'
                skip_section = False
                supplement_lines.append(line)
                continue
                
            # ãã®ä»–ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ##ãƒ¬ãƒ™ãƒ«ï¼‰
            elif line.startswith('## '):
                # é …ç›®å®šç¾©ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†ãƒã‚§ãƒƒã‚¯
                if skip_section:
                    skip_section = False
                    current_section = 'supplement'
                elif current_section == 'conditions':
                    current_section = 'supplement'
                
                supplement_lines.append(line)
                continue
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ|ã§å§‹ã¾ã‚‹è¡Œï¼‰
            elif line.strip().startswith('|') and '|' in line:
                # é …ç›®å®šç¾©ã®ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                continue
                
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¢ƒç•Œã§ã®ç©ºè¡Œå‡¦ç†
            elif line.strip() == '' and skip_section:
                continue
            
            # å†…å®¹ã‚’é©åˆ‡ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«æŒ¯ã‚Šåˆ†ã‘
            if current_section == 'conditions' and not skip_section:
                conditions_lines.append(line)
            elif current_section == 'supplement' and not skip_section:
                supplement_lines.append(line)
        
        # conditionsãŒç©ºã®å ´åˆã¯ç°¡å˜ãªæ¡ä»¶ã‚’ç”Ÿæˆ
        if not conditions_lines:
            conditions = """## è¡¨ç¤ºæ¡ä»¶
- ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿åˆ©ç”¨å¯èƒ½
- é©åˆ‡ãªæ¨©é™ã‚’æŒã¤ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½"""
        else:
            conditions = '\n'.join(conditions_lines).strip()
        
        # supplementã‹ã‚‰ä¸è¦ãªéƒ¨åˆ†ã‚’é™¤å»
        supplement_text = '\n'.join(supplement_lines).strip()
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒé‡è¤‡ã—ã¦ã„ã‚‹å ´åˆã¯é™¤å»
        if supplement_text.startswith('# '):
            supplement_lines_filtered = supplement_text.split('\n')[1:]
            supplement = '\n'.join(supplement_lines_filtered).strip()
        else:
            supplement = supplement_text
        
        return conditions, supplement

    def _extract_from_text(self, text: str, target_type: str) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰è¨­è¨ˆæ›¸ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆWebUI GeneratedDraftå½¢å¼ï¼‰"""
        
        # åŸºæœ¬çš„ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        if target_type == 'screen':
            table_data = [
                {"é …ç›®å": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’è­˜åˆ¥ã™ã‚‹ID"},
                {"é …ç›®å": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "è¡¨ç¤ºç”¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å"},
                {"é …ç›®å": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", "ãƒ‡ãƒ¼ã‚¿å‹": "email", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ­ã‚°ã‚¤ãƒ³ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"}
            ]
        elif target_type == 'api':
            table_data = [
                {"é …ç›®å": "user_id", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ID"},
                {"é …ç›®å": "name", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¦ãƒ¼ã‚¶ãƒ¼å"},
                {"é …ç›®å": "email", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"}
            ]
        else:  # model
            table_data = [
                {"é …ç›®å": "id", "ãƒ‡ãƒ¼ã‚¿å‹": "bigint", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ãƒ—ãƒ©ã‚¤ãƒãƒªã‚­ãƒ¼"},
                {"é …ç›®å": "name", "ãƒ‡ãƒ¼ã‚¿å‹": "varchar(255)", "å¿…é ˆ": "â—‹", "èª¬æ˜": "åå‰"},
                {"é …ç›®å": "created_at", "ãƒ‡ãƒ¼ã‚¿å‹": "timestamp", "å¿…é ˆ": "â—‹", "èª¬æ˜": "ä½œæˆæ—¥æ™‚"}
            ]
        
        # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
        markdown_content = f"""# {target_type.title()}è¨­è¨ˆæ›¸

## æ¦‚è¦
{text[:200]}...

## ç”Ÿæˆæƒ…å ±
- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ç”Ÿæˆæ–¹å¼: AIå‹•çš„ç”Ÿæˆï¼ˆMCP Serverï¼‰

## è©³ç´°
AIç”Ÿæˆã«ã‚ˆã‚‹åŸºæœ¬çš„ãªè¨­è¨ˆæ›¸ã§ã™ã€‚å¿…è¦ã«å¿œã˜ã¦é …ç›®ã‚’è¿½åŠ ãƒ»ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
"""
        
        # WebUI GeneratedDraftå½¢å¼ã«å¤‰æ›
        spreadsheet_cells = self._convert_table_to_cells(table_data)
        conditions, supplement = self._split_markdown_content(markdown_content)
        
        return {
            "type": "mixed",
            "spreadsheetData": spreadsheet_cells,
            "conditions": conditions or markdown_content,
            "supplement": supplement
        }
    
    async def _generate_fallback_design_draft(
        self,
        prompt: str,
        target_type: str,
        project_context: Optional[Dict]
    ) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆï¼ˆWebUI GeneratedDraftå½¢å¼ï¼‰"""
        
        table_data = [
            {"é …ç›®å": "ã‚¨ãƒ©ãƒ¼", "ãƒ‡ãƒ¼ã‚¿å‹": "string", "å¿…é ˆ": "â—‹", "èª¬æ˜": f"ç”Ÿæˆã‚¨ãƒ©ãƒ¼: AI APIã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ"}
        ]
        
        markdown_content = f"""# {target_type.title()}è¨­è¨ˆæ›¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

## âš ï¸ ç”Ÿæˆã‚¨ãƒ©ãƒ¼
AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªè¨­è¨ˆæ›¸ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚

### ã‚¨ãƒ©ãƒ¼è©³ç´°
- ç™ºç”Ÿæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}
- å¯¾è±¡ã‚¿ã‚¤ãƒ—: {target_type}

### å¯¾å‡¦æ–¹æ³•
1. AI APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„

AIç”Ÿæˆã®å¾©æ—§å¾Œã€å†åº¦ç”Ÿæˆè¦æ±‚ã‚’é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        # WebUI GeneratedDraftå½¢å¼ã«å¤‰æ›
        spreadsheet_cells = self._convert_table_to_cells(table_data)
        conditions, supplement = self._split_markdown_content(markdown_content)
        
        return {
            "type": "mixed",
            "spreadsheetData": spreadsheet_cells,
            "conditions": conditions or markdown_content,
            "supplement": supplement,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "fallback",
                "target_type": target_type,
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "fallback_design_draft",
                "ai_provider": "none"
            }
        }
    
    async def _generate_fallback_data(
        self, 
        prompt: str, 
        project_context: Optional[Dict], 
        references: Optional[list]
    ) -> Dict[str, Any]:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿"""
        
        fallback_mermaid = """erDiagram
    USER {
        string id PK
        string name
        string email
        datetime created_at
        datetime updated_at
    }
    
    PROJECT {
        string id PK
        string name
        string description
        string owner_id FK
        datetime created_at
        datetime updated_at
    }
    
    DOCUMENT {
        string id PK
        string project_id FK
        string name
        string type
        json content
        datetime created_at
        datetime updated_at
    }
    
    USER ||--o{ PROJECT : owns
    PROJECT ||--o{ DOCUMENT : contains"""
        
        fallback_supplement = f"""## ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

### ç”Ÿæˆæƒ…å ±
- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}
- **ç”Ÿæˆæ–¹å¼**: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆAIç”Ÿæˆå¤±æ•—ï¼‰

### âš ï¸ æ³¨æ„
AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

1. **APIè¨­å®š**: ç’°å¢ƒå¤‰æ•°ã§AIã‚µãƒ¼ãƒ“ã‚¹ã®èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹
2. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒæ­£å¸¸ã‹
3. **ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ³**: AI APIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹

### åŸºæœ¬ãƒ¢ãƒ‡ãƒ«èª¬æ˜
- **USER**: ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨è€…
- **PROJECT**: è¨­è¨ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ  
- **DOCUMENT**: è¨­è¨ˆæ›¸

AIç”Ÿæˆã®å¾©æ—§å¾Œã€å†åº¦ç”Ÿæˆè¦æ±‚ã‚’é€ä¿¡ã—ã¦ãã ã•ã„ã€‚
"""
        
        return {
            "mermaidCode": fallback_mermaid,
            "supplement": fallback_supplement,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "fallback",
                "project_context": project_context,
                "references": references or [],
                "server_version": "0.1.0",
                "generation_type": "fallback_mermaid",
                "ai_provider": "none"
            }
        }
    
    async def generate_mockup_html(
        self,
        prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """
        AIç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸HTML+CSSç”Ÿæˆ
        
        Args:
            prompt: ç”»é¢ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            context: WebUIãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            project_context: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸHTML+CSSæ–‡å­—åˆ—
        """
        
        print(f"ğŸ¨ AI HTMLç”Ÿæˆè¦æ±‚:")
        print(f"   ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt[:100]}...")
        print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        # HTMLç”Ÿæˆç”¨ã®è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        html_prompt = f"""
ä»¥ä¸‹ã®è¦æ±‚ã«åŸºã¥ã„ã¦ã€å®Œå…¨ã«ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã§å‹•ä½œã™ã‚‹HTML+CSSã®ç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ãªåˆ¶ç´„ã€‘
- å¤–éƒ¨ç”»åƒURLï¼ˆvia.placeholder.comç­‰ï¼‰ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
- ç”»åƒãŒå¿…è¦ãªå ´åˆã¯CSS Gradientã€SVGã€Unicodeæ–‡å­—ï¼ˆçµµæ–‡å­—ï¼‰ã€èƒŒæ™¯è‰²ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒä¸è¦ã§å®Œå…¨ã«ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã§å‹•ä½œã™ã‚‹HTMLã«ã—ã¦ãã ã•ã„
- ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’é©ç”¨ã—ã¦ãã ã•ã„
- ãƒ¢ãƒ€ãƒ³ãªCSSã‚¹ã‚¿ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„

ã€è¦æ±‚å†…å®¹ã€‘
{prompt}

ã€WebUIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘
- è¡¨ç¤ºæ¡ä»¶: {context.get('conditionsMarkdown', 'æŒ‡å®šãªã—') if context else 'æŒ‡å®šãªã—'}
- é …ç›®å®šç¾©: {len(context.get('spreadsheetData', [])) if context else 0}ä»¶

ã€å‡ºåŠ›å½¢å¼ã€‘
HTML+CSSã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã¯ä¸è¦ã§ã™ã€‚
"""
        
        try:
            # åˆ©ç”¨å¯èƒ½ãªAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§HTMLç”Ÿæˆã‚’è©¦è¡Œ
            for provider_name in self.ai_providers:
                try:
                    print(f"ğŸ¤– {provider_name}ã§HTMLç”Ÿæˆã‚’è©¦è¡Œä¸­...")
                    
                    if provider_name == 'bedrock':
                        import boto3
                        bedrock = boto3.client(
                            'bedrock-runtime',
                            aws_access_key_id=self.aws_access_key,
                            aws_secret_access_key=self.aws_secret_key,
                            region_name=self.aws_region
                        )
                        
                        # Claude 3.5 Sonnetã§HTMLç”Ÿæˆ
                        request_body = {
                            "anthropic_version": "bedrock-2023-05-31",
                            "max_tokens": 4000,
                            "temperature": 0.7,
                            "messages": [{
                                "role": "user",
                                "content": html_prompt
                            }]
                        }
                        
                        response = bedrock.invoke_model(
                            modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
                            body=json.dumps(request_body)
                        )
                        
                        response_body = json.loads(response['body'].read())
                        html_result = response_body['content'][0]['text'].strip()
                        
                    elif provider_name == 'openai':
                        import openai
                        client = openai.OpenAI(api_key=self.openai_api_key)
                        
                        response = client.chat.completions.create(
                            model="gpt-4",
                            messages=[{
                                "role": "user",
                                "content": html_prompt
                            }],
                            max_tokens=4000,
                            temperature=0.7
                        )
                        
                        html_result = response.choices[0].message.content.strip()
                    
                    # HTMLéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
                    if '```html' in html_result:
                        html_start = html_result.find('```html') + 7
                        html_end = html_result.find('```', html_start)
                        if html_end != -1:
                            html_result = html_result[html_start:html_end].strip()
                    elif '```' in html_result:
                        html_start = html_result.find('```') + 3
                        html_end = html_result.find('```', html_start)
                        if html_end != -1:
                            html_result = html_result[html_start:html_end].strip()
                    
                    print(f"âœ… {provider_name}ã§HTMLç”ŸæˆæˆåŠŸ")
                    print(f"   HTMLé•·: {len(html_result)} æ–‡å­—")
                    return html_result
                    
                except Exception as e:
                    print(f"âŒ {provider_name}ã§HTMLç”Ÿæˆå¤±æ•—: {e}")
                    continue
            
            # å…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å¤±æ•—ã—ãŸå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯HTML
            print("ğŸ”„ å…¨AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯HTMLã‚’ä½¿ç”¨")
            return await self._generate_fallback_html(prompt, context, project_context)
            
        except Exception as e:
            print(f"âŒ HTMLç”Ÿæˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return await self._generate_fallback_html(prompt, context, project_context)
    
    async def _generate_fallback_html(
        self,
        prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯HTML"""
        
        # é …ç›®å®šç¾©ã‹ã‚‰ç°¡å˜ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆ
        table_rows = ""
        if context and context.get('spreadsheetData'):
            spreadsheet_data = context['spreadsheetData']
            if len(spreadsheet_data) > 0:
                # æœ€åˆã®ã‚·ãƒ¼ãƒˆã®ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é …ç›®ã‚’æŠ½å‡º
                cells = spreadsheet_data[0].get('celldata', [])
                if cells:
                    # è¡Œåˆ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
                    rows = {}
                    for cell in cells:
                        row = cell.get('r', 0)
                        col = cell.get('c', 0)
                        value = cell.get('v', {})
                        if isinstance(value, dict):
                            cell_value = value.get('v', '')
                        else:
                            cell_value = value
                        
                        if row not in rows:
                            rows[row] = {}
                        rows[row][col] = str(cell_value)
                    
                    # ãƒ˜ãƒƒãƒ€ãƒ¼ä»¥å¤–ã®è¡Œã‚’ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã¨ã—ã¦è¿½åŠ 
                    for row_num in sorted(rows.keys()):
                        if row_num > 0:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                            row_data = rows[row_num]
                            cells_html = ""
                            for col in range(4):  # é …ç›®åã€ãƒ‡ãƒ¼ã‚¿å‹ã€å¿…é ˆã€èª¬æ˜
                                cell_value = row_data.get(col, "")
                                cells_html += f"<td>{cell_value}</td>"
                            table_rows += f"<tr>{cells_html}</tr>"
        
        if not table_rows:
            table_rows = """
                <tr><td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ID</td><td>string</td><td>â—‹</td><td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸€æ„è­˜åˆ¥å­</td></tr>
                <tr><td>ãƒ¦ãƒ¼ã‚¶ãƒ¼å</td><td>string</td><td>â—‹</td><td>ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¡¨ç¤ºå</td></tr>
                <tr><td>ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹</td><td>email</td><td>â—‹</td><td>é€£çµ¡ç”¨ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹</td></tr>
            """
        
        fallback_html = f"""
<style>
  .ai-mockup-container {{ 
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 32px; 
    border-radius: 16px; 
    color: #1f2937;
    max-width: 800px;
    margin: 0 auto;
    box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);
  }}
  .ai-mockup-content {{
    background: rgba(255, 255, 255, 0.95);
    padding: 24px;
    border-radius: 12px;
    backdrop-filter: blur(10px);
  }}
  .ai-mockup-title {{ 
    font-size: 2rem; 
    font-weight: 700; 
    margin-bottom: 8px; 
    color: #1e40af;
    text-align: center;
  }}
  .ai-mockup-subtitle {{
    text-align: center;
    color: #6b7280;
    margin-bottom: 24px;
    font-size: 1.1rem;
  }}
  .ai-mockup-table {{ 
    width: 100%; 
    border-collapse: collapse; 
    margin-bottom: 24px;
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
  }}
  .ai-mockup-table th {{ 
    background: linear-gradient(135deg, #3b82f6, #1e40af);
    color: white;
    padding: 16px 12px;
    font-weight: 600;
    text-align: left;
    font-size: 0.9rem;
  }}
  .ai-mockup-table td {{ 
    border-bottom: 1px solid #e5e7eb;
    padding: 12px;
    background: rgba(255, 255, 255, 0.8);
  }}
  .ai-mockup-table tr:hover td {{
    background: rgba(59, 130, 246, 0.1);
  }}
  .ai-mockup-buttons {{
    display: flex;
    gap: 12px;
    justify-content: center;
    flex-wrap: wrap;
  }}
  .ai-mockup-button {{ 
    background: linear-gradient(135deg, #10b981, #059669);
    color: #fff; 
    border: none; 
    border-radius: 8px; 
    padding: 12px 24px; 
    font-size: 1rem; 
    font-weight: 600;
    cursor: pointer;
    transition: all 0.2s;
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
  }}
  .ai-mockup-button:hover {{
    transform: translateY(-1px);
    box-shadow: 0 6px 8px -1px rgba(0, 0, 0, 0.15);
  }}
  .ai-mockup-input {{ 
    border: 2px solid #d1d5db; 
    border-radius: 8px; 
    padding: 12px 16px;
    font-size: 1rem;
    margin-right: 12px;
    margin-bottom: 12px;
    transition: border-color 0.2s;
    background: rgba(255, 255, 255, 0.9);
  }}
  .ai-mockup-input:focus {{
    outline: none;
    border-color: #3b82f6;
    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
  }}
  .ai-mockup-warning {{
    background: rgba(251, 146, 60, 0.1);
    border: 1px solid #f59e0b;
    padding: 16px;
    border-radius: 8px;
    margin-bottom: 16px;
    color: #92400e;
    font-size: 0.9rem;
  }}
  .ai-mockup-warning strong {{
    color: #b45309;
  }}
</style>
<div class="ai-mockup-container">
  <div class="ai-mockup-content">
    <div class="ai-mockup-title">ğŸš€ ç®¡ç†ç”»é¢</div>
    <div class="ai-mockup-subtitle">ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ </div>
    
    <div class="ai-mockup-warning">
      <strong>âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡¨ç¤º:</strong> AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€åŸºæœ¬çš„ãªç”»é¢ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚
      AI APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
    </div>
    
    <table class="ai-mockup-table">
      <thead>
        <tr>
          <th>ğŸ“‹ é …ç›®å</th>
          <th>ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‹</th>
          <th>âœ… å¿…é ˆ</th>
          <th>ğŸ“ èª¬æ˜</th>
        </tr>
      </thead>
      <tbody>
        {table_rows}
      </tbody>
    </table>
    
    <div class="ai-mockup-buttons">
      <input class="ai-mockup-input" placeholder="æ–°ã—ã„é …ç›®ã‚’å…¥åŠ›..." />
      <button class="ai-mockup-button">â• è¿½åŠ </button>
      <button class="ai-mockup-button">âœï¸ ç·¨é›†</button>
      <button class="ai-mockup-button">ğŸ—‘ï¸ å‰Šé™¤</button>
    </div>
  </div>
</div>
"""
        
        return fallback_html
    
    async def generate_modification_proposal(
        self,
        system_prompt: str,
        user_prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """
        AIä¿®æ­£ææ¡ˆç”Ÿæˆ
        
        Args:
            system_prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¿®æ­£ææ¡ˆç”Ÿæˆç”¨ï¼‰
            user_prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¿®æ­£è¦æ±‚ï¼‰
            context: WebUIãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            project_context: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸä¿®æ­£ææ¡ˆãƒ†ã‚­ã‚¹ãƒˆ
        """
        
        print(f"ğŸ”§ AIä¿®æ­£ææ¡ˆç”Ÿæˆè¦æ±‚:")
        print(f"   ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {system_prompt[:100]}...")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {user_prompt[:100]}...")
        print(f"   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        
        try:
            # åˆ©ç”¨å¯èƒ½ãªAIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ä¿®æ­£ææ¡ˆç”Ÿæˆã‚’è©¦è¡Œ
            for provider_name in self.ai_providers:
                try:
                    print(f"ğŸ¤– {provider_name}ã§ä¿®æ­£ææ¡ˆç”Ÿæˆã‚’è©¦è¡Œä¸­...")
                    
                    if provider_name == 'bedrock':
                        import boto3
                        bedrock = boto3.client(
                            'bedrock-runtime',
                            aws_access_key_id=self.aws_access_key,
                            aws_secret_access_key=self.aws_secret_key,
                            region_name=self.aws_region
                        )
                        
                        # Claude 3.5 Sonnetã§ä¿®æ­£ææ¡ˆç”Ÿæˆ
                        request_body = {
                            "anthropic_version": "bedrock-2023-05-31",
                            "max_tokens": 3000,
                            "temperature": 0.3,
                            "messages": [{
                                "role": "user",
                                "content": f"{system_prompt}\n\n{user_prompt}"
                            }]
                        }
                        
                        response = bedrock.invoke_model(
                            modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',
                            body=json.dumps(request_body)
                        )
                        
                        response_body = json.loads(response['body'].read())
                        proposal_result = response_body['content'][0]['text'].strip()
                        
                    elif provider_name == 'openai':
                        import openai
                        client = openai.OpenAI(api_key=self.openai_api_key)
                        
                        response = client.chat.completions.create(
                            model="gpt-4",
                            messages=[{
                                "role": "system",
                                "content": system_prompt
                            }, {
                                "role": "user",
                                "content": user_prompt
                            }],
                            max_tokens=3000,
                            temperature=0.3
                        )
                        
                        proposal_result = response.choices[0].message.content.strip()
                    
                    print(f"âœ… {provider_name}ã§ä¿®æ­£ææ¡ˆç”ŸæˆæˆåŠŸ")
                    print(f"   ä¿®æ­£ææ¡ˆé•·: {len(proposal_result)} æ–‡å­—")
                    return proposal_result
                    
                except Exception as e:
                    print(f"âŒ {provider_name}ã§ä¿®æ­£ææ¡ˆç”Ÿæˆå¤±æ•—: {e}")
                    continue
            
            # å…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å¤±æ•—ã—ãŸå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆ
            print("ğŸ”„ å…¨AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆã‚’ä½¿ç”¨")
            return await self._generate_fallback_modification_proposal(user_prompt, context, project_context)
            
        except Exception as e:
            print(f"âŒ ä¿®æ­£ææ¡ˆç”Ÿæˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return await self._generate_fallback_modification_proposal(user_prompt, context, project_context)
    
    async def _generate_fallback_modification_proposal(
        self,
        user_prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> str:
        """AIç”Ÿæˆå¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¿®æ­£ææ¡ˆ"""
        
        fallback_proposal = f"""```json
{{
  "summary": "ä¿®æ­£ææ¡ˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰",
  "changes": [
    {{
      "target": "conditions",
      "action": "modify",
      "location": "1",
      "originalContent": "ç¾åœ¨ã®å†…å®¹",
      "newContent": "AIç”Ÿæˆã‚¨ãƒ©ãƒ¼ã®ãŸã‚ã€æ‰‹å‹•ã§ã®ä¿®æ­£ã‚’ãŠé¡˜ã„ã—ã¾ã™",
      "reason": "AI APIã«æ¥ç¶šã§ããªã„ãŸã‚ã€å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“",
      "confidence": 0.1
    }}
  ],
  "risks": [
    "AIç”Ÿæˆã«å¤±æ•—ã—ãŸãŸã‚ã€é©åˆ‡ãªä¿®æ­£ææ¡ˆã‚’æä¾›ã§ãã¾ã›ã‚“",
    "æ‰‹å‹•ã§ã®ç¢ºèªã¨ä¿®æ­£ãŒå¿…è¦ã§ã™",
    "AI APIè¨­å®šã®ç¢ºèªãŒå¿…è¦ã§ã™"
  ]
}}
```

**âš ï¸ ä¿®æ­£ææ¡ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼**

AI APIã«æ¥ç¶šã§ããªã„ãŸã‚ã€å…·ä½“çš„ãªä¿®æ­£ææ¡ˆã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

**ã‚¨ãƒ©ãƒ¼è©³ç´°:**
- ç™ºç”Ÿæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: {user_prompt}
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}

**å¯¾å‡¦æ–¹æ³•:**
1. **APIè¨­å®šç¢ºèª**: ç’°å¢ƒå¤‰æ•°ã§AI APIèªè¨¼æƒ…å ±ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒæ­£å¸¸ã‹ç¢ºèª
3. **æ‰‹å‹•ä¿®æ­£**: AIã«ã‚ˆã‚‹è‡ªå‹•ä¿®æ­£ã®ä»£ã‚ã‚Šã«æ‰‹å‹•ã§ä¿®æ­£ã‚’è¡Œã†
4. **å†è©¦è¡Œ**: AI APIã®å¾©æ—§å¾Œã€å†åº¦ä¿®æ­£ææ¡ˆã‚’è¦æ±‚ã™ã‚‹

**æ‰‹å‹•ä¿®æ­£ã®å‚è€ƒ:**
- è¡¨ç¤ºæ¡ä»¶ã‚¿ãƒ–ã§ç›´æ¥Markdownã‚’ç·¨é›†
- é …ç›®å®šç¾©ã‚¿ãƒ–ã§ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå½¢å¼ã§ç·¨é›†
- è£œè¶³èª¬æ˜ã‚¿ãƒ–ã§è¿½åŠ æƒ…å ±ã‚’è¨˜å…¥

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€æ‰‹å‹•ã§ã®ä¿®æ­£ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"""
        
        return fallback_proposal

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
ai_service = AIService()