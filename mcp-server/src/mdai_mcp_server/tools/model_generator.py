# src/mdai_mcp_server/tools/model_generator.py
"""
ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ„ãƒ¼ãƒ«
å›ºå®šMermaidè¿”å´ã«ã‚ˆã‚‹ç–é€šç¢ºèªç”¨å®Ÿè£…
"""

from typing import Dict, Optional, List
from datetime import datetime
import json
from ..ai_service import ai_service

def setup_model_tools(app):
    """ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ„ãƒ¼ãƒ«ã‚’MCPã‚¢ãƒ—ãƒªã«ç™»éŒ²"""
    
    @app.tool()
    async def generate_data_model(
        prompt: str,
        project_context: Optional[Dict] = None,
        references: Optional[List[str]] = None
    ) -> Dict:
        """
        ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ç”Ÿæˆï¼ˆAIå‹•çš„ç”Ÿæˆï¼‰
        
        Args:
            prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ç”Ÿæˆè¦æ±‚
            project_context: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            references: å‚ç…§ã•ã‚Œã‚‹ä»–ã®è¨­è¨ˆæ›¸
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«æƒ…å ±
        """
        
        print(f"ğŸ“¥ AI Data model generation request received:")
        print(f"   Prompt: {prompt}")
        print(f"   Project: {project_context.get('name', 'ä¸æ˜') if project_context else 'ä¸æ˜'}")
        print(f"   References: {references or []}")
        
        try:
            # AIçµŒç”±ã§ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆ
            result = await ai_service.generate_data_model(
                prompt=prompt,
                project_context=project_context,
                references=references,
                current_mermaid_code=""  # ç¾åœ¨ã®Mermaidã‚³ãƒ¼ãƒ‰ï¼ˆæ‹¡å¼µå¯èƒ½ï¼‰
            )
            
            print(f"âœ… AI Data model generated successfully")
            print(f"   Mode: {result['metadata']['mode']}")
            print(f"   AI Provider: {result['metadata']['ai_provider']}")
            mermaid_lines = len(result['mermaidCode'].split('\n'))
            print(f"   Mermaid lines: {mermaid_lines}")
            print(f"   Supplement chars: {len(result['supplement'])}")
            
            return result
            
        except Exception as e:
            print(f"âŒ AI generation error: {e}")
            print(f"ğŸ”„ Falling back to error response")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ˜ç¢ºãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
            error_result = {
                "mermaidCode": """erDiagram
    ERROR {
        string message
        datetime occurred_at
    }""",
                "supplement": f"""## âŒ ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼

### ã‚¨ãƒ©ãƒ¼è©³ç´°
- **ç™ºç”Ÿæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ã‚¨ãƒ©ãƒ¼å†…å®¹**: {str(e)}
- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {prompt}

### å¯¾å‡¦æ–¹æ³•
1. **AI APIè¨­å®šç¢ºèª**: ç’°å¢ƒå¤‰æ•°ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª**: ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šçŠ¶æ³ã‚’ç¢ºèª
3. **å†è©¦è¡Œ**: ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦å®Ÿè¡Œ

### ç’°å¢ƒå¤‰æ•°è¨­å®šä¾‹
```bash
export OPENAI_API_KEY="your-openai-key"
export AWS_ACCESS_KEY_ID="your-aws-key"
export AWS_SECRET_ACCESS_KEY="your-aws-secret"
export AWS_REGION="us-west-2"
```
""",
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "prompt_used": prompt,
                    "mode": "error",
                    "project_context": project_context,
                    "references": references or [],
                    "server_version": "0.1.0",
                    "generation_type": "error_response",
                    "error": str(e)
                }
            }
            
            return error_result
    
    @app.tool()
    async def ping() -> Dict:
        """ç–é€šç¢ºèªç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ„ãƒ¼ãƒ«"""
        
        print("ğŸ“ Ping request received")
        
        result = {
            "status": "ok",
            "message": "MDAI MCP Server is running!",
            "timestamp": datetime.now().isoformat(),
            "server_name": "mdai-model-server",
            "version": "0.1.0",
            "mode": "fixed_response_testing"
        }
        
        print("ğŸ“ Pong response sent")
        
        return result
    
    @app.tool()
    async def get_server_info() -> Dict:
        """ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾—ãƒ„ãƒ¼ãƒ«"""
        
        print("â„¹ï¸ Server info request received")
        
        result = {
            "server_name": "MDAI MCP Server",
            "version": "0.1.0",
            "description": "ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ç”Ÿæˆç”¨MCPã‚µãƒ¼ãƒãƒ¼",
            "mode": "fixed_response_testing",
            "available_tools": [
                "generate_data_model",
                "ping", 
                "get_server_info"
            ],
            "status": "ready",
            "uptime": "running",
            "timestamp": datetime.now().isoformat()
        }
        
        print("â„¹ï¸ Server info response sent")
        
        return result

    # ãƒ„ãƒ¼ãƒ«ç™»éŒ²å®Œäº†ã‚’ãƒ­ã‚°å‡ºåŠ›
    print("ğŸ› ï¸ Model generation tools registered:")
    print("   - generate_data_model: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆå›ºå®šç‰ˆï¼‰")
    print("   - ping: ç–é€šç¢ºèª")
    print("   - get_server_info: ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾—")