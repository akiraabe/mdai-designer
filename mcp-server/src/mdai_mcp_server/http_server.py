# src/mdai_mcp_server/http_server.py
"""
MCP HTTP Server
WebUIã‹ã‚‰ã®HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’MCPãƒ—ãƒ­ãƒˆã‚³ãƒ«ã«å¤‰æ›
"""

from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import json
import asyncio
from datetime import datetime
from typing import Dict, Any, Optional

from .tools.model_generator import setup_model_tools
from .tools.design_draft_generator import setup_design_draft_tools
from .ai_service import ai_service

# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
http_app = FastAPI(title="MDAI MCP HTTP Server", version="0.1.0")

# CORSè¨­å®š
http_app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # Viteé–‹ç™ºã‚µãƒ¼ãƒãƒ¼
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MCPãƒ„ãƒ¼ãƒ«ã®å®Ÿè£…ã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
tools_registry = {}

def register_tools():
    """MCPãƒ„ãƒ¼ãƒ«ã‚’HTTPçµŒç”±ã§å‘¼ã³å‡ºã—å¯èƒ½ã«ã™ã‚‹"""
    
    async def generate_data_model(
        prompt: str,
        project_context: Optional[Dict] = None,
        references: Optional[list] = None
    ) -> Dict:
        """AIå‹•çš„ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆãƒ„ãƒ¼ãƒ«"""
        return await ai_service.generate_data_model(
            prompt=prompt,
            project_context=project_context,
            references=references,
            current_mermaid_code=""
        )

    async def ping() -> Dict:
        """ç–é€šç¢ºèªç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ„ãƒ¼ãƒ«"""
        print("ğŸ“ Ping request received")
        
        result = {
            "status": "ok",
            "message": "MDAI MCP Server is running!",
            "timestamp": datetime.now().isoformat(),
            "server_name": "mdai-model-server",
            "version": "0.1.0",
            "mode": "fixed_response_testing"
        }
        
        print("ğŸ“ Pong response sent")
        return result

    async def get_server_info() -> Dict:
        """ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾—ãƒ„ãƒ¼ãƒ«"""
        print("â„¹ï¸ Server info request received")
        
        result = {
            "server_name": "MDAI MCP Server",
            "version": "0.1.0",
            "description": "ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆæ›¸ç”Ÿæˆç”¨MCPã‚µãƒ¼ãƒãƒ¼",
            "mode": "fixed_response_testing",
            "available_tools": [
                "generate_data_model",
                "ping", 
                "get_server_info"
            ],
            "status": "ready",
            "uptime": "running",
            "timestamp": datetime.now().isoformat()
        }
        
        print("â„¹ï¸ Server info response sent")
        return result

    async def generate_design_draft(
        prompt: str,
        context: Optional[Dict] = None,
        target_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> Dict:
        """è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆãƒ„ãƒ¼ãƒ«"""
        return await ai_service.generate_design_draft(
            prompt=prompt,
            context=context or {},
            target_type=target_type,
            project_context=project_context
        )

    async def generate_chat_response(
        user_message: str,
        context: Optional[Dict] = None,
        document_type: Optional[str] = None,
        project_context: Optional[Dict] = None
    ) -> Dict:
        """ãƒãƒ£ãƒƒãƒˆå¿œç­”ç”Ÿæˆãƒ„ãƒ¼ãƒ«"""
        response = await ai_service.generate_chat_response(
            user_message=user_message,
            context=context or {},
            document_type=document_type,
            project_context=project_context
        )
        return {
            "response": response,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "message_used": user_message,
                "mode": "chat_response",
                "document_type": document_type or "general",
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "ai_chat_response"
            }
        }

    async def generate_mockup_html(
        prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> Dict:
        """HTMLç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸ç”Ÿæˆãƒ„ãƒ¼ãƒ«"""
        html_result = await ai_service.generate_mockup_html(
            prompt=prompt,
            context=context or {},
            project_context=project_context
        )
        return {
            "html": html_result,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "prompt_used": prompt,
                "mode": "mockup_html",
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "ai_mockup_html"
            }
        }

    async def generate_modification_proposal(
        system_prompt: str,
        user_prompt: str,
        context: Optional[Dict] = None,
        project_context: Optional[Dict] = None
    ) -> Dict:
        """ä¿®æ­£ææ¡ˆç”Ÿæˆãƒ„ãƒ¼ãƒ«"""
        proposal_result = await ai_service.generate_modification_proposal(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            context=context or {},
            project_context=project_context
        )
        return {
            "response": proposal_result,
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "system_prompt_used": system_prompt,
                "user_prompt_used": user_prompt,
                "mode": "modification_proposal",
                "project_context": project_context,
                "server_version": "0.1.0",
                "generation_type": "ai_modification_proposal"
            }
        }

    # ãƒ„ãƒ¼ãƒ«ã‚’ç™»éŒ²
    tools_registry["generate_data_model"] = generate_data_model
    tools_registry["generate_design_draft"] = generate_design_draft
    tools_registry["generate_chat_response"] = generate_chat_response
    tools_registry["generate_mockup_html"] = generate_mockup_html
    tools_registry["generate_modification_proposal"] = generate_modification_proposal
    tools_registry["ping"] = ping
    tools_registry["get_server_info"] = get_server_info
    
    print("ğŸ› ï¸ HTTP Server tools registered:")
    print("   - generate_data_model: AIå‹•çš„ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆOpenAI/Bedrockï¼‰")
    print("   - generate_design_draft: AIå‹•çš„è¨­è¨ˆæ›¸ãƒ‰ãƒ©ãƒ•ãƒˆç”Ÿæˆï¼ˆOpenAI/Bedrockï¼‰")
    print("   - generate_chat_response: AIå‹•çš„ãƒãƒ£ãƒƒãƒˆå¿œç­”ç”Ÿæˆï¼ˆOpenAI/Bedrockï¼‰")
    print("   - generate_mockup_html: AIç”»é¢ã‚¤ãƒ¡ãƒ¼ã‚¸HTML+CSSç”Ÿæˆï¼ˆOpenAI/Bedrockï¼‰")
    print("   - generate_modification_proposal: AIä¿®æ­£ææ¡ˆç”Ÿæˆï¼ˆOpenAI/Bedrockï¼‰")
    print("   - ping: ç–é€šç¢ºèª")
    print("   - get_server_info: ã‚µãƒ¼ãƒãƒ¼æƒ…å ±å–å¾—")

# ãƒ„ãƒ¼ãƒ«ç™»éŒ²ã‚’å®Ÿè¡Œ
register_tools()

@http_app.post("/")
async def handle_mcp_request(request: Request):
    """MCPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’HTTPçµŒç”±ã§å‡¦ç†"""
    try:
        # JSONãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£æ
        body = await request.json()
        method = body.get("method")
        params = body.get("params", {})
        request_id = body.get("id")
        
        print(f"ğŸ“¨ MCP HTTP Request: {method}")
        
        # å¯¾å¿œã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—
        if method not in tools_registry:
            raise HTTPException(
                status_code=400, 
                detail=f"Unknown method: {method}"
            )
        
        tool_func = tools_registry[method]
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å±•é–‹ã—ã¦å‘¼ã³å‡ºã—
        if params:
            if isinstance(params, dict):
                result = await tool_func(**params)
            else:
                result = await tool_func(params)
        else:
            result = await tool_func()
        
        # MCPå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”å´
        response = {
            "result": result,
            "id": request_id
        }
        
        print(f"âœ… MCP HTTP Response: {method} completed")
        return response
        
    except Exception as e:
        print(f"âŒ MCP HTTP Error: {e}")
        error_response = {
            "error": {
                "code": -32603,
                "message": str(e)
            },
            "id": body.get("id") if 'body' in locals() else None
        }
        return error_response

@http_app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "status": "ok",
        "server": "MDAI MCP HTTP Server",
        "version": "0.1.0",
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ MDAI MCP HTTP Server starting...")
    print("ğŸ”§ Mode: AI Dynamic Generation (OpenAI/Bedrock)")
    print("ğŸ“¡ Running HTTP server on port 3001")
    
    uvicorn.run(http_app, host="0.0.0.0", port=3001)